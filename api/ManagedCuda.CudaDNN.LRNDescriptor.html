<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Class LRNDescriptor
   | ManagedCuda.NETStandard </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Class LRNDescriptor
   | ManagedCuda.NETStandard ">
    <meta name="generator" content="docfx 2.35.4.0">
    
    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    <meta property="docfx:rel" content="../">
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src="../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">
        
        <div id="search-results">
          <div class="search-list"></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="ManagedCuda.CudaDNN.LRNDescriptor">
  
  
  <h1 id="ManagedCuda_CudaDNN_LRNDescriptor" data-uid="ManagedCuda.CudaDNN.LRNDescriptor" class="text-break">Class LRNDescriptor
  </h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="inheritance">
    <h5>Inheritance</h5>
    <div class="level0"><span class="xref">System.Object</span></div>
    <div class="level1"><span class="xref">LRNDescriptor</span></div>
  </div>
  <div classs="implements">
    <h5>Implements</h5>
    <div><span class="xref">System.IDisposable</span></div>
  </div>
  <div class="inheritedMembers">
    <h5>Inherited Members</h5>
    <div>
      <span class="xref">System.Object.Equals(System.Object)</span>
    </div>
    <div>
      <span class="xref">System.Object.Equals(System.Object, System.Object)</span>
    </div>
    <div>
      <span class="xref">System.Object.GetHashCode()</span>
    </div>
    <div>
      <span class="xref">System.Object.GetType()</span>
    </div>
    <div>
      <span class="xref">System.Object.MemberwiseClone()</span>
    </div>
    <div>
      <span class="xref">System.Object.ReferenceEquals(System.Object, System.Object)</span>
    </div>
    <div>
      <span class="xref">System.Object.ToString()</span>
    </div>
  </div>
  <h6><strong>Namespace</strong>: <a class="xref" href="ManagedCuda.CudaDNN.html">ManagedCuda.CudaDNN</a></h6>
  <h6><strong>Assembly</strong>: CudaDNN.dll</h6>
  <h5 id="ManagedCuda_CudaDNN_LRNDescriptor_syntax">Syntax</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public class LRNDescriptor : IDisposable</code></pre>
  </div>
  <h3 id="constructors">Constructors
  </h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor__ctor_ManagedCuda_CudaDNN_CudaDNNContext_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.%23ctor(ManagedCuda.CudaDNN.CudaDNNContext)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L42">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor__ctor_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.#ctor*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor__ctor_ManagedCuda_CudaDNN_CudaDNNContext_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.#ctor(ManagedCuda.CudaDNN.CudaDNNContext)">LRNDescriptor(CudaDNNContext)</h4>
  <div class="markdown level1 summary"></div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public LRNDescriptor(CudaDNNContext context)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.CudaDNNContext.html">CudaDNNContext</a></td>
        <td><span class="parametername">context</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h3 id="properties">Properties
  </h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_Desc.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.Desc%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L92">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_Desc_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Desc*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_Desc" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Desc">Desc</h4>
  <div class="markdown level1 summary"><p>Returns the inner handle.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public cudnnLRNDescriptor Desc { get; }</code></pre>
  </div>
  <h5 class="propertyValue">Property Value</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnLRNDescriptor.html">cudnnLRNDescriptor</a></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <h3 id="methods">Methods
  </h3>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationBackward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnDivNormMode%2CSystem.Double%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Double%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L561">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationBackward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationBackward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnDivisiveNormalizationBackward(cudnnDivNormMode, Double, cudnnTensorDescriptor, CUdeviceptr, CUdeviceptr, CUdeviceptr, CUdeviceptr, CUdeviceptr, Double, cudnnTensorDescriptor, CUdeviceptr, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the backward DivisiveNormalization layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnDivisiveNormalizationBackward(cudnnDivNormMode mode, double alpha, cudnnTensorDescriptor xDesc, CUdeviceptr x, CUdeviceptr means, CUdeviceptr dy, CUdeviceptr temp, CUdeviceptr temp2, double beta, cudnnTensorDescriptor dXdMeansDesc, CUdeviceptr dx, CUdeviceptr dMeans)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnDivNormMode.html">cudnnDivNormMode</a></td>
        <td><span class="parametername">mode</span></td>
        <td><p>DivisiveNormalization layer mode of operation. Currently only
CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
is performed using the means input tensor that is expected to be
precomputed by the user.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor and pointers in device memory for the bottom layer's
data and means. (Bottom layer is the earlier layer in the computation
graph during inference). Note: the means tensor is expected to be
precomputed by the user. It can also contain any valid values (not required
to be actual means, and can be for instance a result of a convolution with
a Gaussian kernel).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Tensor descriptor and pointers in device memory for the bottom layer's
data and means. (Bottom layer is the earlier layer in the computation
graph during inference). Note: the means tensor is expected to be
precomputed by the user. It can also contain any valid values (not required
to be actual means, and can be for instance a result of a convolution with
a Gaussian kernel).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">means</span></td>
        <td><p>Tensor descriptor and pointers in device memory for the bottom layer's
data and means. (Bottom layer is the earlier layer in the computation
graph during inference). Note: the means tensor is expected to be
precomputed by the user. It can also contain any valid values (not required
to be actual means, and can be for instance a result of a convolution with
a Gaussian kernel).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dy</span></td>
        <td><p>Tensor pointer in device memory for the top layer's cumulative loss
differential data (error backpropagation). (Top layer is the later layer in
the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the backward pass. These tensors do not have
to be preserved from forward to backward pass. Both use srcDesc as a
descriptor.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp2</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the backward pass. These tensors do not have
to be preserved from forward to backward pass. Both use srcDesc as a
descriptor.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">dXdMeansDesc</span></td>
        <td><p>Tensor descriptor for destDataDiff and destMeansDiff.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dx</span></td>
        <td><p>Tensor pointers (in device memory) for the bottom layer's resulting
differentials (data and means). Both share the same descriptor.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dMeans</span></td>
        <td><p>Tensor pointers (in device memory) for the bottom layer's resulting
differentials (data and means). Both share the same descriptor.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationBackward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnDivNormMode%2CSystem.Single%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Single%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L493">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationBackward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationBackward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationBackward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnDivisiveNormalizationBackward(cudnnDivNormMode, Single, cudnnTensorDescriptor, CUdeviceptr, CUdeviceptr, CUdeviceptr, CUdeviceptr, CUdeviceptr, Single, cudnnTensorDescriptor, CUdeviceptr, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the backward DivisiveNormalization layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnDivisiveNormalizationBackward(cudnnDivNormMode mode, float alpha, cudnnTensorDescriptor xDesc, CUdeviceptr x, CUdeviceptr means, CUdeviceptr dy, CUdeviceptr temp, CUdeviceptr temp2, float beta, cudnnTensorDescriptor dXdMeansDesc, CUdeviceptr dx, CUdeviceptr dMeans)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnDivNormMode.html">cudnnDivNormMode</a></td>
        <td><span class="parametername">mode</span></td>
        <td><p>DivisiveNormalization layer mode of operation. Currently only
CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
is performed using the means input tensor that is expected to be
precomputed by the user.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor and pointers in device memory for the bottom layer's
data and means. (Bottom layer is the earlier layer in the computation
graph during inference). Note: the means tensor is expected to be
precomputed by the user. It can also contain any valid values (not required
to be actual means, and can be for instance a result of a convolution with
a Gaussian kernel).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Tensor descriptor and pointers in device memory for the bottom layer's
data and means. (Bottom layer is the earlier layer in the computation
graph during inference). Note: the means tensor is expected to be
precomputed by the user. It can also contain any valid values (not required
to be actual means, and can be for instance a result of a convolution with
a Gaussian kernel).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">means</span></td>
        <td><p>Tensor descriptor and pointers in device memory for the bottom layer's
data and means. (Bottom layer is the earlier layer in the computation
graph during inference). Note: the means tensor is expected to be
precomputed by the user. It can also contain any valid values (not required
to be actual means, and can be for instance a result of a convolution with
a Gaussian kernel).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dy</span></td>
        <td><p>Tensor pointer in device memory for the top layer's cumulative loss
differential data (error backpropagation). (Top layer is the later layer in
the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the backward pass. These tensors do not have
to be preserved from forward to backward pass. Both use srcDesc as a
descriptor.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp2</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the backward pass. These tensors do not have
to be preserved from forward to backward pass. Both use srcDesc as a
descriptor.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">dXdMeansDesc</span></td>
        <td><p>Tensor descriptor for destDataDiff and destMeansDiff.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dx</span></td>
        <td><p>Tensor pointers (in device memory) for the bottom layer's resulting
differentials (data and means). Both share the same descriptor.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dMeans</span></td>
        <td><p>Tensor pointers (in device memory) for the bottom layer's resulting
differentials (data and means). Both share the same descriptor.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationForward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnDivNormMode%2CSystem.Double%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Double%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L425">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationForward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationForward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnDivisiveNormalizationForward(cudnnDivNormMode, Double, cudnnTensorDescriptor, CUdeviceptr, CUdeviceptr, CUdeviceptr, CUdeviceptr, Double, cudnnTensorDescriptor, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the forward DivisiveNormalization layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnDivisiveNormalizationForward(cudnnDivNormMode mode, double alpha, cudnnTensorDescriptor xDesc, CUdeviceptr x, CUdeviceptr means, CUdeviceptr temp, CUdeviceptr temp2, double beta, cudnnTensorDescriptor yDesc, CUdeviceptr y)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnDivNormMode.html">cudnnDivNormMode</a></td>
        <td><span class="parametername">mode</span></td>
        <td><p>DivisiveNormalization layer mode of operation. Currently only
CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
is performed using the means input tensor that is expected to be
precomputed by the user.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors. Note that
srcDesc is shared between srcData, srcMeansData, tempData, tempData2
tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Input tensor data pointer in device memory.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">means</span></td>
        <td><p>Input means tensor data pointer in device memory. Note that this tensor
can be NULL (in that case it's values are assumed to be zero during the
computation). This tensor also doesn't have to contain means, these can
be any values, a frequently used variation is a result of convolution with a
normalized positive kernel (such as Gaussian).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the forward pass. These tensors do not have
to be preserved as inputs from forward to the backward pass. Both use
srcDesc as a descriptor.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp2</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the forward pass. These tensors do not have
to be preserved as inputs from forward to the backward pass. Both use
srcDesc as a descriptor.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">yDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors. Note that
srcDesc is shared between srcData, srcMeansData, tempData, tempData2
tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">y</span></td>
        <td><p>Pointer in device memory to a tensor for the result of the forward DivisiveNormalization pass.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationForward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnDivNormMode%2CSystem.Single%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Single%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L372">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationForward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnDivisiveNormalizationForward_ManagedCuda_CudaDNN_cudnnDivNormMode_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_BasicTypes_CUdeviceptr_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnDivisiveNormalizationForward(ManagedCuda.CudaDNN.cudnnDivNormMode,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnDivisiveNormalizationForward(cudnnDivNormMode, Single, cudnnTensorDescriptor, CUdeviceptr, CUdeviceptr, CUdeviceptr, CUdeviceptr, Single, cudnnTensorDescriptor, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the forward DivisiveNormalization layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnDivisiveNormalizationForward(cudnnDivNormMode mode, float alpha, cudnnTensorDescriptor xDesc, CUdeviceptr x, CUdeviceptr means, CUdeviceptr temp, CUdeviceptr temp2, float beta, cudnnTensorDescriptor yDesc, CUdeviceptr y)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnDivNormMode.html">cudnnDivNormMode</a></td>
        <td><span class="parametername">mode</span></td>
        <td><p>DivisiveNormalization layer mode of operation. Currently only
CUDNN_DIVNORM_PRECOMPUTED_MEANS is implemented. Normalization
is performed using the means input tensor that is expected to be
precomputed by the user.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors. Note that
srcDesc is shared between srcData, srcMeansData, tempData, tempData2
tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Input tensor data pointer in device memory.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">means</span></td>
        <td><p>Input means tensor data pointer in device memory. Note that this tensor
can be NULL (in that case it's values are assumed to be zero during the
computation). This tensor also doesn't have to contain means, these can
be any values, a frequently used variation is a result of convolution with a
normalized positive kernel (such as Gaussian).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the forward pass. These tensors do not have
to be preserved as inputs from forward to the backward pass. Both use
srcDesc as a descriptor.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">temp2</span></td>
        <td><p>Temporary tensors in device memory. These are used for computing
intermediate values during the forward pass. These tensors do not have
to be preserved as inputs from forward to the backward pass. Both use
srcDesc as a descriptor.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">yDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors. Note that
srcDesc is shared between srcData, srcMeansData, tempData, tempData2
tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">y</span></td>
        <td><p>Pointer in device memory to a tensor for the result of the forward DivisiveNormalization pass.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelBackward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Double__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Double__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnLRNMode%2CSystem.Double%40%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Double%40%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L317">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelBackward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelBackward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Double__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Double__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnLRNCrossChannelBackward(cudnnLRNMode, ref Double, cudnnTensorDescriptor, CUdeviceptr, cudnnTensorDescriptor, CUdeviceptr, cudnnTensorDescriptor, CUdeviceptr, ref Double, cudnnTensorDescriptor, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the backward LRN layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnLRNCrossChannelBackward(cudnnLRNMode lrnMode, ref double alpha, cudnnTensorDescriptor yDesc, CUdeviceptr y, cudnnTensorDescriptor dyDesc, CUdeviceptr dy, cudnnTensorDescriptor xDesc, CUdeviceptr x, ref double beta, cudnnTensorDescriptor dxDesc, CUdeviceptr dx)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnLRNMode.html">cudnnLRNMode</a></td>
        <td><span class="parametername">lrnMode</span></td>
        <td><p>LRN layer mode of operation. Currently only
CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
performed along the tensor's dimA[1].</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">yDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph during
inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">y</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph during
inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">dyDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the top layer's
cumulative loss differential data (error backpropagation). (Top layer is the
later layer in the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dy</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the top layer's
cumulative loss differential data (error backpropagation). (Top layer is the
later layer in the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph
during inference). Note that these values are not modified during
backpropagation.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph
during inference). Note that these values are not modified during
backpropagation.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">dxDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
cumulative loss differential data (error backpropagation). (Bottom layer is
the earlier layer in the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dx</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
cumulative loss differential data (error backpropagation). (Bottom layer is
the earlier layer in the computation graph during inference).</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelBackward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Single__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Single__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnLRNMode%2CSystem.Single%40%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Single%40%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L259">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelBackward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelBackward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Single__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Single__ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelBackward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single@,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnLRNCrossChannelBackward(cudnnLRNMode, ref Single, cudnnTensorDescriptor, CUdeviceptr, cudnnTensorDescriptor, CUdeviceptr, cudnnTensorDescriptor, CUdeviceptr, ref Single, cudnnTensorDescriptor, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the backward LRN layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnLRNCrossChannelBackward(cudnnLRNMode lrnMode, ref float alpha, cudnnTensorDescriptor yDesc, CUdeviceptr y, cudnnTensorDescriptor dyDesc, CUdeviceptr dy, cudnnTensorDescriptor xDesc, CUdeviceptr x, ref float beta, cudnnTensorDescriptor dxDesc, CUdeviceptr dx)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnLRNMode.html">cudnnLRNMode</a></td>
        <td><span class="parametername">lrnMode</span></td>
        <td><p>LRN layer mode of operation. Currently only
CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
performed along the tensor's dimA[1].</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">yDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph during
inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">y</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph during
inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">dyDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the top layer's
cumulative loss differential data (error backpropagation). (Top layer is the
later layer in the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dy</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the top layer's
cumulative loss differential data (error backpropagation). (Top layer is the
later layer in the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph
during inference). Note that these values are not modified during
backpropagation.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
data. (Bottom layer is the earlier layer in the computation graph
during inference). Note that these values are not modified during
backpropagation.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">dxDesc</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
cumulative loss differential data (error backpropagation). (Bottom layer is
the earlier layer in the computation graph during inference).</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">dx</span></td>
        <td><p>Tensor descriptor and pointer in device memory for the bottom layer's
cumulative loss differential data (error backpropagation). (Bottom layer is
the earlier layer in the computation graph during inference).</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelForward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnLRNMode%2CSystem.Double%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Double%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L204">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelForward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelForward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Double_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Double,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnLRNCrossChannelForward(cudnnLRNMode, Double, cudnnTensorDescriptor, CUdeviceptr, Double, cudnnTensorDescriptor, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the forward LRN layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnLRNCrossChannelForward(cudnnLRNMode lrnMode, double alpha, cudnnTensorDescriptor xDesc, CUdeviceptr x, double beta, cudnnTensorDescriptor yDesc, CUdeviceptr y)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnLRNMode.html">cudnnLRNMode</a></td>
        <td><span class="parametername">lrnMode</span></td>
        <td><p>LRN layer mode of operation. Currently only
CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
performed along the tensor's dimA[1].</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Input tensor data pointer in device memory.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">yDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">y</span></td>
        <td><p>Output tensor data pointer in device memory.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelForward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnLRNMode%2CSystem.Single%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr%2CSystem.Single%2CManagedCuda.CudaDNN.cudnnTensorDescriptor%2CManagedCuda.BasicTypes.CUdeviceptr)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L172">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelForward_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_cudnnLRNCrossChannelForward_ManagedCuda_CudaDNN_cudnnLRNMode_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_System_Single_ManagedCuda_CudaDNN_cudnnTensorDescriptor_ManagedCuda_BasicTypes_CUdeviceptr_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.cudnnLRNCrossChannelForward(ManagedCuda.CudaDNN.cudnnLRNMode,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr,System.Single,ManagedCuda.CudaDNN.cudnnTensorDescriptor,ManagedCuda.BasicTypes.CUdeviceptr)">cudnnLRNCrossChannelForward(cudnnLRNMode, Single, cudnnTensorDescriptor, CUdeviceptr, Single, cudnnTensorDescriptor, CUdeviceptr)</h4>
  <div class="markdown level1 summary"><p>This function performs the forward LRN layer computation.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void cudnnLRNCrossChannelForward(cudnnLRNMode lrnMode, float alpha, cudnnTensorDescriptor xDesc, CUdeviceptr x, float beta, cudnnTensorDescriptor yDesc, CUdeviceptr y)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnLRNMode.html">cudnnLRNMode</a></td>
        <td><span class="parametername">lrnMode</span></td>
        <td><p>LRN layer mode of operation. Currently only
CUDNN_LRN_CROSS_CHANNEL_DIM1 is implemented. Normalization is
performed along the tensor's dimA[1].</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">alpha</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">xDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">x</span></td>
        <td><p>Input tensor data pointer in device memory.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Single</span></td>
        <td><span class="parametername">beta</span></td>
        <td><p>Pointer to scaling factors (in host memory) used to blend the layer output
value with prior value in the destination tensor as follows: dstValue =
alpha[0]*resultValue + beta[0]*priorDstValue. Please refer to this section
for additional details.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.CudaDNN.cudnnTensorDescriptor.html">cudnnTensorDescriptor</a></td>
        <td><span class="parametername">yDesc</span></td>
        <td><p>Tensor descriptor objects for the input and output tensors.</p>
</td>
      </tr>
      <tr>
        <td><a class="xref" href="ManagedCuda.BasicTypes.CUdeviceptr.html">CUdeviceptr</a></td>
        <td><span class="parametername">y</span></td>
        <td><p>Output tensor data pointer in device memory.</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_Dispose.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.Dispose%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L65">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_Dispose_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Dispose*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_Dispose" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Dispose">Dispose()</h4>
  <div class="markdown level1 summary"><p>Dispose</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void Dispose()</code></pre>
  </div>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_Dispose_System_Boolean_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.Dispose(System.Boolean)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L75">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_Dispose_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Dispose*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_Dispose_System_Boolean_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Dispose(System.Boolean)">Dispose(Boolean)</h4>
  <div class="markdown level1 summary"><p>For IDisposable</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected virtual void Dispose(bool fDisposing)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.Boolean</span></td>
        <td><span class="parametername">fDisposing</span></td>
        <td></td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_Finalize.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.Finalize%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L55">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_Finalize_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Finalize*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_Finalize" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.Finalize">Finalize()</h4>
  <div class="markdown level1 summary"><p>For dispose</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">protected void Finalize()</code></pre>
  </div>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_GetLRNDescriptor_System_UInt32__System_Double__System_Double__System_Double__.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.GetLRNDescriptor(System.UInt32%40%2CSystem.Double%40%2CSystem.Double%40%2CSystem.Double%40)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L142">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_GetLRNDescriptor_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.GetLRNDescriptor*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_GetLRNDescriptor_System_UInt32__System_Double__System_Double__System_Double__" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.GetLRNDescriptor(System.UInt32@,System.Double@,System.Double@,System.Double@)">GetLRNDescriptor(ref UInt32, ref Double, ref Double, ref Double)</h4>
  <div class="markdown level1 summary"><p>This function retrieves values stored in the previously initialized LRN descriptor object.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void GetLRNDescriptor(ref uint lrnN, ref double lrnAlpha, ref double lrnBeta, ref double lrnK)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.UInt32</span></td>
        <td><span class="parametername">lrnN</span></td>
        <td><p>Pointers to receive values of parameters stored in the descriptor object.
See cudnnSetLRNDescriptor for more details. Any of these pointers can be
NULL (no value is returned for the corresponding parameter).</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">lrnAlpha</span></td>
        <td><p>Pointers to receive values of parameters stored in the descriptor object.
See cudnnSetLRNDescriptor for more details. Any of these pointers can be
NULL (no value is returned for the corresponding parameter).</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">lrnBeta</span></td>
        <td><p>Pointers to receive values of parameters stored in the descriptor object.
See cudnnSetLRNDescriptor for more details. Any of these pointers can be
NULL (no value is returned for the corresponding parameter).</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">lrnK</span></td>
        <td><p>Pointers to receive values of parameters stored in the descriptor object.
See cudnnSetLRNDescriptor for more details. Any of these pointers can be
NULL (no value is returned for the corresponding parameter).</p>
</td>
      </tr>
    </tbody>
  </table>
  <span class="small pull-right mobile-hide">
    <span class="divider">|</span>
    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor_SetLRNDescriptor_System_UInt32_System_Double_System_Double_System_Double_.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor.SetLRNDescriptor(System.UInt32%2CSystem.Double%2CSystem.Double%2CSystem.Double)%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A">Improve this Doc</a>
  </span>
  <span class="small pull-right mobile-hide">
    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L116">View Source</a>
  </span>
  <a id="ManagedCuda_CudaDNN_LRNDescriptor_SetLRNDescriptor_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.SetLRNDescriptor*"></a>
  <h4 id="ManagedCuda_CudaDNN_LRNDescriptor_SetLRNDescriptor_System_UInt32_System_Double_System_Double_System_Double_" data-uid="ManagedCuda.CudaDNN.LRNDescriptor.SetLRNDescriptor(System.UInt32,System.Double,System.Double,System.Double)">SetLRNDescriptor(UInt32, Double, Double, Double)</h4>
  <div class="markdown level1 summary"><p>This function initializes a previously created LRN descriptor object.</p>
</div>
  <div class="markdown level1 conceptual"></div>
  <h5 class="decalaration">Declaration</h5>
  <div class="codewrapper">
    <pre><code class="lang-csharp hljs">public void SetLRNDescriptor(uint lrnN, double lrnAlpha, double lrnBeta, double lrnK)</code></pre>
  </div>
  <h5 class="parameters">Parameters</h5>
  <table class="table table-bordered table-striped table-condensed">
    <thead>
      <tr>
        <th>Type</th>
        <th>Name</th>
        <th>Description</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><span class="xref">System.UInt32</span></td>
        <td><span class="parametername">lrnN</span></td>
        <td><p>Normalization window width in elements. LRN layer uses a window
[center-lookBehind, center+lookAhead], where lookBehind =
floor( (lrnN-1)/2 ), lookAhead = lrnN-lookBehind-1. So for n=10,
the window is [k-4...k...k+5] with a total of 10 samples. For
DivisiveNormalization layer the window has the same extents as above in
all 'spatial' dimensions (dimA[2], dimA[3], dimA[4]). By default lrnN is set
to 5 in cudnnCreateLRNDescriptor.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">lrnAlpha</span></td>
        <td><p>Value of the alpha variance scaling parameter in the normalization
formula. Inside the library code this value is divided by the
window width for LRN and by (window width)^#spatialDimensions
for DivisiveNormalization. By default this value is set to 1e-4 in
cudnnCreateLRNDescriptor.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">lrnBeta</span></td>
        <td><p>Value of the beta power parameter in the normalization formula. By
default this value is set to 0.75 in cudnnCreateLRNDescriptor.</p>
</td>
      </tr>
      <tr>
        <td><span class="xref">System.Double</span></td>
        <td><span class="parametername">lrnK</span></td>
        <td><p>Value of the k parameter in normalization formula. By default this value is set to 2.0.</p>
</td>
      </tr>
    </tbody>
  </table>
  <h3 id="implements">Implements</h3>
  <div>
      <span class="xref">System.IDisposable</span>
  </div>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                  <li>
                    <a href="https://github.com/surban/managedCuda/new/master/apiSpec/new?filename=ManagedCuda_CudaDNN_LRNDescriptor.md&amp;value=---%0Auid%3A%20ManagedCuda.CudaDNN.LRNDescriptor%0Asummary%3A%20'*You%20can%20override%20summary%20for%20the%20API%20here%20using%20*MARKDOWN*%20syntax'%0A---%0A%0A*Please%20type%20below%20more%20information%20about%20this%20API%3A*%0A%0A" class="contribution-link">Improve this Doc</a>
                  </li>
                  <li>
                    <a href="https://github.com/surban/managedCuda/blob/master/CudaDNN/LRNDescriptor.cs/#L32" class="contribution-link">View Source</a>
                  </li>
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
