<!DOCTYPE html>
<!--[if IE]><![endif]-->
<html>
  
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <title>Namespace ManagedCuda.NPP
   | ManagedCuda.NETStandard </title>
    <meta name="viewport" content="width=device-width">
    <meta name="title" content="Namespace ManagedCuda.NPP
   | ManagedCuda.NETStandard ">
    <meta name="generator" content="docfx 2.35.4.0">
    
    <link rel="shortcut icon" href="../favicon.ico">
    <link rel="stylesheet" href="../styles/docfx.vendor.css">
    <link rel="stylesheet" href="../styles/docfx.css">
    <link rel="stylesheet" href="../styles/main.css">
    <meta property="docfx:navrel" content="../toc.html">
    <meta property="docfx:tocrel" content="toc.html">
    
    <meta property="docfx:rel" content="../">
    
  </head>
  <body data-spy="scroll" data-target="#affix" data-offset="120">
    <div id="wrapper">
      <header>
        
        <nav id="autocollapse" class="navbar navbar-inverse ng-scope" role="navigation">
          <div class="container">
            <div class="navbar-header">
              <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
              </button>
              
              <a class="navbar-brand" href="../index.html">
                <img id="logo" class="svg" src="../logo.svg" alt="">
              </a>
            </div>
            <div class="collapse navbar-collapse" id="navbar">
              <form class="navbar-form navbar-right" role="search" id="search">
                <div class="form-group">
                  <input type="text" class="form-control" id="search-query" placeholder="Search" autocomplete="off">
                </div>
              </form>
            </div>
          </div>
        </nav>
        
        <div class="subnav navbar navbar-default">
          <div class="container hide-when-search" id="breadcrumb">
            <ul class="breadcrumb">
              <li></li>
            </ul>
          </div>
        </div>
      </header>
      <div class="container body-content">
        
        <div id="search-results">
          <div class="search-list"></div>
          <div class="sr-items">
            <p><i class="glyphicon glyphicon-refresh index-loading"></i></p>
          </div>
          <ul id="pagination"></ul>
        </div>
      </div>
      <div role="main" class="container body-content hide-when-search">
        
        <div class="sidenav hide-when-search">
          <a class="btn toc-toggle collapse" data-toggle="collapse" href="#sidetoggle" aria-expanded="false" aria-controls="sidetoggle">Show / Hide Table of Contents</a>
          <div class="sidetoggle collapse" id="sidetoggle">
            <div id="sidetoc"></div>
          </div>
        </div>
        <div class="article row grid-right">
          <div class="col-md-10">
            <article class="content wrap" id="_content" data-uid="ManagedCuda.NPP">
  
  <h1 id="ManagedCuda_NPP" data-uid="ManagedCuda.NPP" class="text-break">Namespace ManagedCuda.NPP
  </h1>
  <div class="markdown level0 summary"></div>
  <div class="markdown level0 conceptual"></div>
  <div class="markdown level0 remarks"></div>
    <h3 id="classes">Classes
  </h3>
      <h4><a class="xref" href="ManagedCuda.NPP.JPEGCompression.html">JPEGCompression</a></h4>
      <section><p>The JPEG standard defines a flow of level shift, DCT and quantization for
forward JPEG transform and inverse level shift, IDCT and de-quantization
for inverse JPEG transform. This group has the functions for both forward
and inverse functions.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPException.html">NPPException</a></h4>
      <section><p>Exception thrown in NPP library if a native NPP function returns a negative error code</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16sC1.html">NPPImage_16sC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16sC2.html">NPPImage_16sC2</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16sC3.html">NPPImage_16sC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16sC4.html">NPPImage_16sC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16scC1.html">NPPImage_16scC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16scC2.html">NPPImage_16scC2</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16scC3.html">NPPImage_16scC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16scC4.html">NPPImage_16scC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16uC1.html">NPPImage_16uC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16uC2.html">NPPImage_16uC2</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16uC3.html">NPPImage_16uC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_16uC4.html">NPPImage_16uC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32fC1.html">NPPImage_32fC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32fC3.html">NPPImage_32fC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32fC4.html">NPPImage_32fC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32fcC1.html">NPPImage_32fcC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32fcC2.html">NPPImage_32fcC2</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32fcC3.html">NPPImage_32fcC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32fcC4.html">NPPImage_32fcC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32sC1.html">NPPImage_32sC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32sC3.html">NPPImage_32sC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32sC4.html">NPPImage_32sC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32scC1.html">NPPImage_32scC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32scC2.html">NPPImage_32scC2</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32scC3.html">NPPImage_32scC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32scC4.html">NPPImage_32scC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32uC1.html">NPPImage_32uC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_32uC4.html">NPPImage_32uC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8sC1.html">NPPImage_8sC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8sC2.html">NPPImage_8sC2</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8sC3.html">NPPImage_8sC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8sC4.html">NPPImage_8sC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8uC1.html">NPPImage_8uC1</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8uC2.html">NPPImage_8uC2</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8uC3.html">NPPImage_8uC3</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImage_8uC4.html">NPPImage_8uC4</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPImageBase.html">NPPImageBase</a></h4>
      <section><p>Abstract base class for derived NPP typed images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.html">NPPNativeMethods</a></h4>
      <section><p>C# Wrapper-Methods for NPP functions defined in npp.h, nppversion.h, nppcore.h, nppi.h, npps.h, nppdefs.h</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPCore.html">NPPNativeMethods.NPPCore</a></h4>
      <section><p>nppcore.h</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.html">NPPNativeMethods.NPPi</a></h4>
      <section><p>nppi.h</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Abs.html">NPPNativeMethods.NPPi.Abs</a></h4>
      <section><p>Absolute value of each pixel value in an image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AbsDiff.html">NPPNativeMethods.NPPi.AbsDiff</a></h4>
      <section><p>Pixel by pixel absolute difference between two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AbsDiffConst.html">NPPNativeMethods.NPPi.AbsDiffConst</a></h4>
      <section><p>Determines absolute difference between each pixel of an image and a constant value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Add.html">NPPNativeMethods.NPPi.Add</a></h4>
      <section><p>Pixel by pixel addition of two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AddConst.html">NPPNativeMethods.NPPi.AddConst</a></h4>
      <section><p>Adds a constant value to each pixel of an image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AddProduct.html">NPPNativeMethods.NPPi.AddProduct</a></h4>
      <section><p>Pixel by pixel addition of product of pixels from two source images to floating point pixel values of destination image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AddSquare.html">NPPNativeMethods.NPPi.AddSquare</a></h4>
      <section><p>Pixel by pixel addition of squared pixels from source image to floating point pixel values of destination image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AddWeighted.html">NPPNativeMethods.NPPi.AddWeighted</a></h4>
      <section><p>Pixel by pixel addition of alpha weighted pixel values from a source image to floating point pixel values of destination image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AffinTransforms.html">NPPNativeMethods.NPPi.AffinTransforms</a></h4>
      <section><p>Affine warping, affine transform calculation
Affine warping of an image is the transform of image pixel positions,
defined by the following formulas:
\f[
X_{new} = C_{00} * x + C_{01} * y + C_{02} \qquad
Y_{new} = C_{10} * x + C_{11} * y + C_{12} \qquad
C = \left[ \matrix{C_{00} &amp; C_{01} &amp; C_{02} \cr C_{10} &amp; C_{11} &amp; C_{12} } \right]
\f]
That is, any pixel with coordinates
\f$(X_{new},Y_{new})\f$ in the transformed image is sourced from
coordinates \f$(x,y)\f$ in the original image. The mapping \f$C\f$ is completely
specified by 6 values
\f$C_{ij}, i=\overline{0,1}, j=\overline{0,2}\f$.
The transform maps parallel lines to parallel
lines and preserves ratios of distances of points to lines.
Implementation specific properties are
discussed in each function's documentation.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AlphaComp.html">NPPNativeMethods.NPPi.AlphaComp</a></h4>
      <section><p>Composite two images using alpha opacity values contained in each image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AlphaCompConst.html">NPPNativeMethods.NPPi.AlphaCompConst</a></h4>
      <section><p>Composite two images using constant alpha values.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AlphaPremul.html">NPPNativeMethods.NPPi.AlphaPremul</a></h4>
      <section><p>Premultiplies image pixels by image alpha opacity values.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AlphaPremulConst.html">NPPNativeMethods.NPPi.AlphaPremulConst</a></h4>
      <section><p>Premultiplies pixels of an image using a constant alpha value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.And.html">NPPNativeMethods.NPPi.And</a></h4>
      <section><p>Pixel by pixel logical and of images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AndConst.html">NPPNativeMethods.NPPi.AndConst</a></h4>
      <section><p>Pixel by pixel logical and of an image with a constant.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AverageError.html">NPPNativeMethods.NPPi.AverageError</a></h4>
      <section><p>Primitives for computing the average error between two images.<p>
Given two images Src1 and Src2 both with width W and height H.<p>
If the image is in complex format, the absolute value is used for computation.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.AverageRelativeError.html">NPPNativeMethods.NPPi.AverageRelativeError</a></h4>
      <section><p>Primitives for computing the average relative error between two images.<p>
If the image is in complex format, the absolute value is used for computation.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BGRToCbYCr.html">NPPNativeMethods.NPPi.BGRToCbYCr</a></h4>
      <section><p>BGR To CbYCr Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BGRToHLS.html">NPPNativeMethods.NPPi.BGRToHLS</a></h4>
      <section><p>BGR to HLS</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BGRToLab.html">NPPNativeMethods.NPPi.BGRToLab</a></h4>
      <section><p>BGR to LAB</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BGRToYCbCr.html">NPPNativeMethods.NPPi.BGRToYCbCr</a></h4>
      <section><p>BGR to YCbCr Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BGRToYCrCb.html">NPPNativeMethods.NPPi.BGRToYCrCb</a></h4>
      <section><p>BGR to YCrCb Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BGRToYUV.html">NPPNativeMethods.NPPi.BGRToYUV</a></h4>
      <section><p>BGR to YUV color conversion.<p>
Here is how NPP converts gamma corrected RGB or BGR to YUV. <p>
For digital RGB values in the range [0..255], Y has the range [0..255], U varies in the range [-112..+112],
and V in the range [-157..+157]. <p>
To fit in the range of [0..255], a constant value of 128 is added to computed U and V values, and V is then saturated.</p>
<p>
Npp32f nY =  0.299F * R + 0.587F * G + 0.114F * B; <p>
Npp32f nU = (0.492F * ((Npp32f)nB - nY)) + 128.0F; <p>
Npp32f nV = (0.877F * ((Npp32f)nR - nY)) + 128.0F; <p>
if (nV > 255.0F) nV = 255.0F;<p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BGRToYUV420.html">NPPNativeMethods.NPPi.BGRToYUV420</a></h4>
      <section><p>BGR To YUV420 Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.BitDepthConversion.html">NPPNativeMethods.NPPi.BitDepthConversion</a></h4>
      <section><p>Convert bit-depth up and down.<p>
The integer conversion methods do not involve any scaling. Conversions that reduce bit-depth saturate
values exceeding the reduced range to the range's maximum/minimum value.
When converting from floating-point values to integer values, a rounding mode can be specified. After rounding
to integer values the values get saturated to the destination data type's range.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CbYCrToBGR.html">NPPNativeMethods.NPPi.CbYCrToBGR</a></h4>
      <section><p>CbYCrToBGR Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CbYCrToRGB.html">NPPNativeMethods.NPPi.CbYCrToRGB</a></h4>
      <section><p>CbYCr to RGB Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorDebayer.html">NPPNativeMethods.NPPi.ColorDebayer</a></h4>
      <section><p>Grayscale Color Filter Array to RGB Color Debayer conversion. Generates one RGB color pixel for every grayscale source pixel.<p>
Source and destination images must have even width and height.  Missing pixel colors are generated using bilinear interpolation
with chroma correlation of generated green values (eInterpolation MUST be set to 0). eGrid allows the user to specify the Bayer grid
registration position at source image location oSrcROI.x, oSrcROI.y relative to pSrc. Possible registration positions are:<p>
BGGR | RGGB | GBRG | GRBG<p>
B G || R G || G B || G R<p>
G R || G B || R G || B G<p>
If it becomes necessary to access source pixels outside source image then the source image borders are mirrored.<p>
<p>Here is how the algorithm works.  R, G, and B base pixels from the source image are used unmodified.  To generate R values for those
G pixels, the average of R(x - 1, y) and R(x + 1, y) or R(x, y - 1) and R(x, y + 1) is used depending on whether the left and right
or top and bottom pixels are R base pixels.  To generate B values for those G pixels, the same algorithm is used using nearest B values.
For an R base pixel, if there are no B values in the upper, lower, left, or right adjacent pixels then B is the average of B values
in the 4 diagonal (G base) pixels.  The same algorithm is used using R values to generate the R value of a B base pixel.
Chroma correlation is applied to generated G values only, for a B base pixel G(x - 1, y) and G(x + 1, y) are averaged or G(x, y - 1)
and G(x, y + 1) are averaged depending on whether the absolute difference between B(x, y) and the average of B(x - 2, y) and B(x + 2, y)
is smaller than the absolute difference between B(x, y) and the average of B(x, y - 2) and B(x, y + 2). For an R base pixel the same
algorithm is used testing against the surrounding R values at those offsets.  If the horizontal and vertical differences are the same
at one of those pixels then the average of the four left, right, upper and lower G values is used instead.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorLUT.html">NPPNativeMethods.NPPi.ColorLUT</a></h4>
      <section><p>Perform image color processing using members of various types of color look up tables.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorLUTCubic.html">NPPNativeMethods.NPPi.ColorLUTCubic</a></h4>
      <section><p>Perform image color processing using linear interpolation between members of various types of color look up tables.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorLUTLinear.html">NPPNativeMethods.NPPi.ColorLUTLinear</a></h4>
      <section><p>Perform image color processing using linear interpolation between members of various types of color look up tables.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorLUTPalette.html">NPPNativeMethods.NPPi.ColorLUTPalette</a></h4>
      <section><p>Perform image color processing using various types of bit range restricted palette color look up tables.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorLUTTrilinear.html">NPPNativeMethods.NPPi.ColorLUTTrilinear</a></h4>
      <section><p>Perform image color processing using 3D trilinear interpolation between members of various types of color look up tables.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorProcessing.html">NPPNativeMethods.NPPi.ColorProcessing</a></h4>
      <section><p>Color manipuliation functions.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorToGray.html">NPPNativeMethods.NPPi.ColorToGray</a></h4>
      <section><p>RGB Color to Gray conversion using user supplied conversion coefficients.<p>
Here is how NPP converts gamma corrected RGB Color to Gray using user supplied conversion coefficients.<p>
<pre><code>nGray =  aCoeffs[0] * R + aCoeffs[1] * G + aCoeffs[2] * B; </code></pre>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorTwist.html">NPPNativeMethods.NPPi.ColorTwist</a></h4>
      <section><p>Perform color twist pixel processing.  Color twist consists of applying the following formula to each
image pixel using coefficients from the user supplied color twist host matrix array as follows where
dst[x] and src[x] represent destination pixel and source pixel channel or plane x.<p>
dst[0] = aTwist[0][0] * src[0] + aTwist[0][1] * src[1] + aTwist[0][2] * src[2] + aTwist[0][3]<p>
dst[1] = aTwist[1][0] * src[0] + aTwist[1][1] * src[1] + aTwist[1][2] * src[2] + aTwist[1][3]<p>
dst[2] = aTwist[2][0] * src[0] + aTwist[2][1] * src[1] + aTwist[2][2] * src[2] + aTwist[2][3]<p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ColorTwistBatch.html">NPPNativeMethods.NPPi.ColorTwistBatch</a></h4>
      <section><p>Perform color twist pixel batch processing.  Color twist consists of applying the following formula to each
image pixel using coefficients from one or more user supplied color twist device memory matrix arrays as follows where
dst[x] and src[x] represent destination pixel and source pixel channel or plane x.The full sized
coefficient matrix should be sent for all pixel channel sizes, the function will process the appropriate
coefficients and channels for the corresponding pixel size.  ColorTwistBatch generally takes the same parameter list as ColorTwist
except that there is a list of N instances of those parameters (N &gt; 1) and that list is passed in device memory; The matrix
pointers referenced for each image in the batch also need to point to device memory matrix values.A convenient
data structure is provided that allows for easy initialization of the parameter lists.The only restriction on these functions is
that there is one single ROI which is applied respectively to each image in the batch.  The primary purpose of this function is to
provide improved performance for batches of smaller images as long as GPU resources are available.  Therefore it is recommended
that the function not be used for very large images as there may not be resources available for processing several large images
simultaneously.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Compare.html">NPPNativeMethods.NPPi.Compare</a></h4>
      <section><p>Compare the pixels of two images and create a binary result image. In case of multi-channel
image types, the condition must be fulfilled for all channels, otherwise the comparison
is considered false.<p>
The &quot;binary&quot; result image is of type 8u_C1. False is represented by 0, true by NPP_MAX_8U.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CompColorKey.html">NPPNativeMethods.NPPi.CompColorKey</a></h4>
      <section><p>Composition color key</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ComplexImageMorphology.html">NPPNativeMethods.NPPi.ComplexImageMorphology</a></h4>
      <section><p>Complex image morphological operations.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CompressionDCT.html">NPPNativeMethods.NPPi.CompressionDCT</a></h4>
      <section><p>Image compression primitives.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Convolution.html">NPPNativeMethods.NPPi.Convolution</a></h4>
      <section><p>General purpose 2D convolution filters.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CopyConstBorder.html">NPPNativeMethods.NPPi.CopyConstBorder</a></h4>
      <section><p>Methods for copying images and padding borders with a constant, user-specifiable color.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CopyReplicateBorder.html">NPPNativeMethods.NPPi.CopyReplicateBorder</a></h4>
      <section><p>Methods for copying images and padding borders with a replicates of the nearest source image pixel color.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CopySubpix.html">NPPNativeMethods.NPPi.CopySubpix</a></h4>
      <section><p>Functions for copying linearly interpolated images using source image subpixel coordinates</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CopyWrapBorder.html">NPPNativeMethods.NPPi.CopyWrapBorder</a></h4>
      <section><p>Methods for copying images and padding borders with wrapped replications of the source image pixel colors.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.CountInRange.html">NPPNativeMethods.NPPi.CountInRange</a></h4>
      <section><p>Primitives for computing the amount of pixels that fall into the specified intensity range.
The lower bound and the upper bound are inclusive.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Dilate3x3Border.html">NPPNativeMethods.NPPi.Dilate3x3Border</a></h4>
      <section><p>Dilation using a 3x3 mask with the anchor at its center pixel with border control.<p>
If any portion of the mask overlaps the source image boundary the requested border type
operation is applied to all mask pixels which fall outside of the source image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.DilationWithBorderControl.html">NPPNativeMethods.NPPi.DilationWithBorderControl</a></h4>
      <section><p>Dilation with border control.
Dilation computes the output pixel as the maximum pixel value of the pixels
under the mask. Pixels who's corresponding mask values are zero do not
participate in the maximum search.<p>
If any portion of the mask overlaps the source image boundary the requested border type
operation is applied to all mask pixels which fall outside of the source image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Div.html">NPPNativeMethods.NPPi.Div</a></h4>
      <section><p>Pixel by pixel division of two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.DivConst.html">NPPNativeMethods.NPPi.DivConst</a></h4>
      <section><p>Divides each pixel of an image by a constant value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.DivRound.html">NPPNativeMethods.NPPi.DivRound</a></h4>
      <section><p>Pixel by pixel division of two images using result rounding modes.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.DotProd.html">NPPNativeMethods.NPPi.DotProd</a></h4>
      <section><p>Primitives for computing the dot product of two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Dup.html">NPPNativeMethods.NPPi.Dup</a></h4>
      <section><p>Functions for duplicating a single channel image in a multiple channel image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Erode3x3Border.html">NPPNativeMethods.NPPi.Erode3x3Border</a></h4>
      <section><p>Erosion using a 3x3 mask with the anchor at its center pixel with border control.<p>
If any portion of the mask overlaps the source image boundary the requested border type
operation is applied to all mask pixels which fall outside of the source image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ErosionWithBorderControl.html">NPPNativeMethods.NPPi.ErosionWithBorderControl</a></h4>
      <section><p>Erosion computes the output pixel as the minimum pixel value of the pixels
under the mask. Pixels who's corresponding mask values are zero do not
participate in the minimum search.<p>
If any portion of the mask overlaps the source image boundary the requested border type
operation is applied to all mask pixels which fall outside of the source image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Exp.html">NPPNativeMethods.NPPi.Exp</a></h4>
      <section><p>Exponential value of each pixel in an image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterBilateralGaussBorder.html">NPPNativeMethods.NPPi.FilterBilateralGaussBorder</a></h4>
      <section><p>Filters the image using a bilateral Gaussian filter kernel with border control:<p>
If any portion of the mask overlaps the source image boundary the requested border type operation is applied to all mask pixels
which fall outside of the source image.<p>
For this filter the anchor point is always the central element of the kernel. <p>
Coefficients of the bilateral filter kernel depend on their position in the kernel and
on the value of some source image pixels overlayed by the filter kernel. <p>
Only source image pixels with both coordinates divisible by nDistanceBetweenSrcPixels are used in calculations.
The value of an output pixel \f$d\f$ is <p>
\f[d = \frac{\sum_{h=-nRadius}^{nRadius}\sum_{w=-nRadius}^{nRadius}W1(h,w)\cdot W2(h,w)\cdot S(h,w)}{\sum_{h=-nRadius}^{nRadius}\sum_{w=-nRadius}^{nRadius}W1(h,w)\cdot W2(h,w)}\f]
where h and w are the corresponding kernel width and height indexes,
S(h,w) is the value of the source image pixel overlayed by filter kernel position (h,w),
W1(h,w) is func(nValSquareSigma, (S(h,w) - S(0,0))) where S(0,0) is the value of the source image pixel at the center of the kernel,
W2(h,w) is func(nPosSquareSigma, sqrt(h<em>h+w</em>w)), and func is the following formula
\f[func(S,I) = exp(-\frac{I^2}{2.0F\cdot S^2})\f]<p>
Currently only the NPP_BORDER_REPLICATE border type operations are supported.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterBorder.html">NPPNativeMethods.NPPi.FilterBorder</a></h4>
      <section><p>General purpose 2D convolution filter with border control.<p>
Pixels under the mask are multiplied by the respective weights in the mask
and the results are summed. Before writing the result pixel the sum is scaled
back via division by nDivisor. If any portion of the mask overlaps the source
image boundary the requested border type operation is applied to all mask pixels
which fall outside of the source image. <p>
Currently only the <a class="xref" href="ManagedCuda.NPP.NppiBorderType.html#ManagedCuda_NPP_NppiBorderType_Replicate">Replicate</a> and <a class="xref" href="ManagedCuda.NPP.NppiBorderType.html#ManagedCuda_NPP_NppiBorderType_Mirror">Mirror</a> border type operation are supported.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterBorder32f.html">NPPNativeMethods.NPPi.FilterBorder32f</a></h4>
      <section><p>General purpose 2D convolution filter using floating-point weights with border control.<p>
Pixels under the mask are multiplied by the respective weights in the mask
and the results are summed. Before writing the result pixel the sum is scaled
back via division by nDivisor. If any portion of the mask overlaps the source
image boundary the requested border type operation is applied to all mask pixels
which fall outside of the source image. <p>
Currently only the <a class="xref" href="ManagedCuda.NPP.NppiBorderType.html#ManagedCuda_NPP_NppiBorderType_Replicate">Replicate</a> and <a class="xref" href="ManagedCuda.NPP.NppiBorderType.html#ManagedCuda_NPP_NppiBorderType_Mirror">Mirror</a> border type operation are supported.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterCannyBorder.html">NPPNativeMethods.NPPi.FilterCannyBorder</a></h4>
      <section><p>Performs Canny edge detection on a single channel 8-bit grayscale image and outputs a single channel 8-bit image consisting of 0x00 and 0xFF
values with 0xFF representing edge pixels.  The algorithm consists of three phases.  The first phase generates two output images consisting
of a single channel 16-bit signed image containing magnitude values and a single channel 32-bit floating point image containing the angular
direction of those magnitude values.   This phase is accomplished by calling the appropriate GradientVectorBorder filter function based on
the filter type, filter mask size, and norm type requested.  The next phase uses those magnitude and direction images to suppress non-maximum
magnitude values which are lower than the values of either of its two nearest neighbors in the same direction as the test magnitude pixel in
the 3x3 surrounding magnitude pixel neighborhood.  This phase outputs a new magnitude image with non-maximum pixel values suppressed.  Finally, in the
third phase, the new magnitude image is passed through a hysteresis threshold filter that filters out any magnitude values that are not connected
to another edge magnitude value.   In this phase, any magnitude value above the high threshold value is automatically accepted, any magnitude
value below the low threshold value is automatically rejected.  For magnitude values that lie between the low and high threshold, values are
only accepted if one of their two neighbors in the same direction in the 3x3 neighborhood around them lies above the low threshold value.  In other words,
if they are connected to an active edge.   J. Canny recommends that the ratio of high to low threshold limit be in the range two or three to one,
based on predicted signal-to-noise ratios. The final output of the third phase consists of a single channel 8-bit unsigned image of 0x00 and 0xFF
values based on whether they are accepted or rejected during threshold testing.</p>
<p>Currently only the NPP_BORDER_REPLICATE border type operation is supported.  Borderless output can be accomplished by using a
larger source image than the destination and adjusting oSrcSize and oSrcOffset parameters accordingly.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterGaussBorder.html">NPPNativeMethods.NPPi.FilterGaussBorder</a></h4>
      <section><p>If any portion of the mask overlaps the source
image boundary the requested border type operation is applied to all mask pixels
which fall outside of the source image.<p>
Currently only the NPP_BORDER_REPLICATE and NPP_BORDER_MIRROR border type operation is supported.<p>
Filters the image using a Gaussian filter kernel:<p>
1/16 2/16 1/16<p>
2/16 4/16 2/16<p>
1/16 2/16 1/16<p>
<p> or <p>
2/571 7/571 12/571 7/571 2/571<p>
7/571 31/571 52/571 31/571 7/571<p>
12/571 52/571 127/571 52/571 12/571<p>
7/571 31/571 52/571 31/571 7/571<p>
2/571 7/571 12/571 7/571 2/571<p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterGaussPyramid.html">NPPNativeMethods.NPPi.FilterGaussPyramid</a></h4>
      <section><p>Filters the image using a separable Gaussian filter kernel with user supplied floating point coefficients with downsampling and border control.
If the downsampling rate is equivalent to an integer value then unnecessary source pixels are just skipped.
If any portion of the mask overlaps the source image boundary the requested border type operation is applied to all mask pixels
which fall outside of the source image.
Filters the image using a separable Gaussian filter kernel with user supplied floating point coefficients with upsampling and border control.
If the upsampling rate is equivalent to an integer value then unnecessary source pixels are just skipped.
If any portion of the mask overlaps the source image boundary the requested border type operation is applied to all mask pixels
which fall outside of the source image.
Currently only the <a class="xref" href="ManagedCuda.NPP.NppiBorderType.html#ManagedCuda_NPP_NppiBorderType_Replicate">Replicate</a> and <a class="xref" href="ManagedCuda.NPP.NppiBorderType.html#ManagedCuda_NPP_NppiBorderType_Mirror">Mirror</a> border type operation are supported.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterHarrisCornersBorder.html">NPPNativeMethods.NPPi.FilterHarrisCornersBorder</a></h4>
      <section><p>Performs Harris Corner detection on a single channel 8-bit grayscale image and outputs a single channel 32-bit floating point image
consisting the corner response at each pixel of the image.  The algorithm consists of two phases.  The first phase generates the floating
point product of XX, YY, and XY gradients at each pixel in the image.  The type of gradient used is controlled by the eFilterType and eMaskSize parameters.
The second phase averages those products over a window of either 3x3 or 5x5 pixels around the center pixel then generates the Harris corner
response at that pixel which is output in the destination image. The Harris response value is determined as H = ((XX///YY - XY///XY) -
(nK///((XX + YY)///(XX + YY))))///nScale.</p>
<p>Currently only the NPP_BORDER_REPLICATE border type operation is supported.  Borderless output can be accomplished by using a
larger source image than the destination and adjusting oSrcSize and oSrcOffset parameters accordingly.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterHoughLine.html">NPPNativeMethods.NPPi.FilterHoughLine</a></h4>
      <section><p>Extracts Hough lines from a single channel 8-bit binarized (0, 255) source feature (canny edges, etc.) image and outputs a list of lines in point polar format
representing the length(rho) and angle(theta) of each line from the origin of the normal to the line using the formula rho = x cos(theta) + y sin(theta).
The level of discretization, nDelta, is specified as an input parameter.The performance and effectiveness of this function highly depends on
this parameter with higher performance for larger numbers and more detailed results for lower numbers.  Also, lines are not guaranteed to
be added to the pDeviceLines list in the same order from one call to the next. However, all of the same lines will still be generated as long as
nMaxLineCount is set large enough so that they all can fit in the list. To convert lines in point polar format back to cartesian lines
use the following formula:</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterScharrHorizBorder.html">NPPNativeMethods.NPPi.FilterScharrHorizBorder</a></h4>
      <section><p>Filters the image using a horizontal Scharr filter kernel with border control:<p>
3  10  3<p>
0  0   0 <p>
-3 -10 -3</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterScharrVertBorder.html">NPPNativeMethods.NPPi.FilterScharrVertBorder</a></h4>
      <section><p>Filters the image using a vertical Scharr filter kernel with border control:<p>
3  10  3<p>
0  0   0 <p>
-3 -10 -3</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterSobelCrossBorder.html">NPPNativeMethods.NPPi.FilterSobelCrossBorder</a></h4>
      <section><p>Filters the image using a second cross derivative Sobel filter kernel with border control.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterSobelHorizBorder.html">NPPNativeMethods.NPPi.FilterSobelHorizBorder</a></h4>
      <section><p>Filters the image using a horizontal Sobel filter kernel with border control.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterSobelHorizSecondBorder.html">NPPNativeMethods.NPPi.FilterSobelHorizSecondBorder</a></h4>
      <section><p>Filters the image using a second derivative, horizontal Sobel filter kernel with border control.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterSobelVertBorder.html">NPPNativeMethods.NPPi.FilterSobelVertBorder</a></h4>
      <section><p>Filters the image using a vertical Sobel filter kernel with border control.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterSobelVertSecondBorder.html">NPPNativeMethods.NPPi.FilterSobelVertSecondBorder</a></h4>
      <section><p>Filters the image using a second derivative, vertical Sobel filter kernel with border control.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterThresholdAdaptiveBoxBorder.html">NPPNativeMethods.NPPi.FilterThresholdAdaptiveBoxBorder</a></h4>
      <section><p>Computes the average pixel values of the pixels under a square mask with border control.
If any portion of the mask overlaps the source image boundary the requested
border type operation is applied to all mask pixels which fall outside of the source image.
Once the neighborhood average around a source pixel is determined the souce pixel is compared to the average - nDelta
and if the source pixel is greater than that average the corresponding destination pixel is set to nValGT, otherwise nValLE.
Currently only the NPP_BORDER_REPLICATE border type operation is supported.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FilterWienerBorder.html">NPPNativeMethods.NPPi.FilterWienerBorder</a></h4>
      <section><p>Noise removal filtering of an image using an adaptive Wiener filter with border control.</p>
<p>
Pixels under the source mask are used to generate statistics about the local neighborhood 
which are then used to control the amount of adaptive noise filtering locally applied.
<p>
Currently only the NPP_BORDER_REPLICATE border type operation is supported.
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.FixedFilters.html">NPPNativeMethods.NPPi.FixedFilters</a></h4>
      <section><p>Fixed filters perform linear filtering operations (i.e. convolutions) with predefined kernels of fixed sizes.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Gamma.html">NPPNativeMethods.NPPi.Gamma</a></h4>
      <section><p>Gamma correction</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.GeometricTransforms.html">NPPNativeMethods.NPPi.GeometricTransforms</a></h4>
      <section><p>Routines manipulating an image's geometry.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.GetResizeRect.html">NPPNativeMethods.NPPi.GetResizeRect</a></h4>
      <section><p>Returns NppiRect which represents the offset and size of the destination rectangle that would be generated by
resizing the source NppiRect by the requested scale factors and shifts.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.GradientColorToGray.html">NPPNativeMethods.NPPi.GradientColorToGray</a></h4>
      <section><p>RGB Color to Gray Gradient conversion using user selected gradient distance method.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.GradientVectorPrewittBorder.html">NPPNativeMethods.NPPi.GradientVectorPrewittBorder</a></h4>
      <section><p>RGB Color to Prewitt Gradient Vector conversion using user selected fixed mask size and gradient distance method.
Functions support up to 4 optional single channel output gradient vectors, X (vertical), Y (horizontal), magnitude, and angle
with user selectable distance methods.  Output for a particular vector is disabled by supplying a NULL pointer for that
vector. X and Y gradient vectors are in cartesian form in the destination data type.<br>
Magnitude vectors are polar gradient form in the destination data type, angle is always in floating point polar gradient format.
Only fixed mask sizes of 3x3 are supported.
Only nppiNormL1 (sum) and nppiNormL2 (sqrt of sum of squares) distance methods are currently supported.</p>
<p>Currently only the NPP_BORDER_REPLICATE border type operation is supported.  Borderless output can be accomplished by using a
larger source image than the destination and adjusting oSrcSize and oSrcOffset parameters accordingly.</p>
<p>For the C1R versions of the function the pDstMag output image value for L1 normalization consists of
the absolute value of the pDstX value plus the absolute value of the pDstY value at that particular image pixel location.
For the C1R versions of the function the pDstMag output image value for L2 normalization consists of
the square root of the pDstX value squared plus the pDstY value squared at that particular image pixel location.
For the C1R versions of the function the pDstAngle output image value consists of the arctangent (atan2) of
the pDstY value and the pDstX value at that particular image pixel location.</p>
<p>For the C3C1R versions of the function, regardless of the selected normalization method,
the L2 normalization value is first determined for each or the pDstX and pDstY values for each source channel then the largest L2
normalization value (largest gradient) is used to select which of the 3 pDstX channel values are output to the pDstX image or
pDstY channel values are output to the pDstY image.
For the C3C1R versions of the function the pDstMag output image value for L1 normalizaton consists of the same technique
used for the C1R version for each source image channel.  Then the largest L2 normalization value is again used to select which
of the 3 pDstMag channel values to output to the pDstMag image.
For the C3C1R versions of the function the pDstMag output image value for L2 normalizaton consists of just outputting
the largest per source channel L2 normalization value to the pDstMag image.
For the C3C1R versions of the function the pDstAngle output image value consists of the same technique used for the C1R version
calculated for each source image channel.  Then the largest L2 normalization value is again used to select which of the 3 angle
values to output to the pDstAngle image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.GradientVectorScharrBorder.html">NPPNativeMethods.NPPi.GradientVectorScharrBorder</a></h4>
      <section><p>RGB Color to Scharr Gradient Vector conversion using user selected fixed mask size and gradient distance method.
Functions support up to 4 optional single channel output gradient vectors, X (vertical), Y (horizontal), magnitude, and angle
with user selectable distance methods.  Output for a particular vector is disabled by supplying a NULL pointer for that
vector. X and Y gradient vectors are in cartesian form in the destination data type.<br>
Magnitude vectors are polar gradient form in the destination data type, angle is always in floating point polar gradient format.
Only fixed mask sizes of 3x3 are supported.
Only nppiNormL1 (sum) and nppiNormL2 (sqrt of sum of squares) distance methods are currently supported.</p>
<p>Currently only the NPP_BORDER_REPLICATE border type operation is supported.  Borderless output can be accomplished by using a
larger source image than the destination and adjusting oSrcSize and oSrcOffset parameters accordingly.</p>
<p>For the C1R versions of the function the pDstMag output image value for L1 normalization consists of
the absolute value of the pDstX value plus the absolute value of the pDstY value at that particular image pixel location.
For the C1R versions of the function the pDstMag output image value for L2 normalization consists of
the square root of the pDstX value squared plus the pDstY value squared at that particular image pixel location.
For the C1R versions of the function the pDstAngle output image value consists of the arctangent (atan2) of
the pDstY value and the pDstX value at that particular image pixel location.</p>
<p>For the C3C1R versions of the function, regardless of the selected normalization method,
the L2 normalization value is first determined for each or the pDstX and pDstY values for each source channel then the largest L2
normalization value (largest gradient) is used to select which of the 3 pDstX channel values are output to the pDstX image or
pDstY channel values are output to the pDstY image.
For the C3C1R versions of the function the pDstMag output image value for L1 normalizaton consists of the same technique
used for the C1R version for each source image channel.  Then the largest L2 normalization value is again used to select which
of the 3 pDstMag channel values to output to the pDstMag image.
For the C3C1R versions of the function the pDstMag output image value for L2 normalizaton consists of just outputting
the largest per source channel L2 normalization value to the pDstMag image.
For the C3C1R versions of the function the pDstAngle output image value consists of the same technique used for the C1R version
calculated for each source image channel.  Then the largest L2 normalization value is again used to select which of the 3 angle
values to output to the pDstAngle image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.GradientVectorSobelBorder.html">NPPNativeMethods.NPPi.GradientVectorSobelBorder</a></h4>
      <section><p>RGB Color to Sobel Gradient Vector conversion using user selected fixed mask size and gradient distance method.
Functions support up to 4 optional single channel output gradient vectors, X (vertical), Y (horizontal), magnitude, and angle
with user selectable distance methods.  Output for a particular vector is disabled by supplying a NULL pointer for that
vector. X and Y gradient vectors are in cartesian form in the destination data type.<br>
Magnitude vectors are polar gradient form in the destination data type, angle is always in floating point polar gradient format.
Only fixed mask sizes of 3x3 and 5x5 are supported.
Only nppiNormL1 (sum) and nppiNormL2 (sqrt of sum of squares) distance methods are currently supported.</p>
<p>Currently only the NPP_BORDER_REPLICATE border type operation is supported.  Borderless output can be accomplished by using a
larger source image than the destination and adjusting oSrcSize and oSrcOffset parameters accordingly.</p>
<p>For the C1R versions of the function the pDstMag output image value for L1 normalization consists of
the absolute value of the pDstX value plus the absolute value of the pDstY value at that particular image pixel location.
For the C1R versions of the function the pDstMag output image value for L2 normalization consists of
the square root of the pDstX value squared plus the pDstY value squared at that particular image pixel location.
For the C1R versions of the function the pDstAngle output image value consists of the arctangent (atan2) of
the pDstY value and the pDstX value at that particular image pixel location.</p>
<p>For the C3C1R versions of the function, regardless of the selected normalization method,
the L2 normalization value is first determined for each or the pDstX and pDstY values for each source channel then the largest L2
normalization value (largest gradient) is used to select which of the 3 pDstX channel values are output to the pDstX image or
pDstY channel values are output to the pDstY image.
For the C3C1R versions of the function the pDstMag output image value for L1 normalizaton consists of the same technique
used for the C1R version for each source image channel.  Then the largest L2 normalization value is again used to select which
of the 3 pDstMag channel values to output to the pDstMag image.
For the C3C1R versions of the function the pDstMag output image value for L2 normalizaton consists of just outputting
the largest per source channel L2 normalization value to the pDstMag image.
For the C3C1R versions of the function the pDstAngle output image value consists of the same technique used for the C1R version
calculated for each source image channel.  Then the largest L2 normalization value is again used to select which of the 3 angle
values to output to the pDstAngle image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Histogram.html">NPPNativeMethods.NPPi.Histogram</a></h4>
      <section><p>Histogram.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.HistogramOfOrientedGradientsBorder.html">NPPNativeMethods.NPPi.HistogramOfOrientedGradientsBorder</a></h4>
      <section><p>Performs Histogram Of Oriented Gradients operation on source image generating separate windows of Histogram Descriptors for each requested location.</p>
<p>
This function implements the simplest form of functionality described by N.Dalal and B.Triggs.Histograms of Oriented Gradients for Human Detection.INRIA, 2005. <p>
It supports overlapped contrast normalized block histogram output with L2 normalization only, no threshold clipping, and no pre or post gaussian smoothing of input images or
histogram output values. It supports both single channel grayscale source images and three channel color images.For color images, the color channel with the
highest magnitude value is used as that pixel&apos;s magnitude. Output is row order only. 
 Descriptors are output consecutively with no separation padding if multiple descriptor output is requested (one desriptor per source image location).
 For example, common HOG parameters are 9 histogram bins per 8 by 8 pixel cell, 2 by 2 cells per block, 
 with a descriptor window size of 64 horizontal by 128 vertical pixels yielding 7 by 15 overlapping blocks 
 (1 cell overlap in both horizontal and vertical directions).  This results in 9 bins* 4 cells* 7 horizontal overlapping blocks* 15 vertical overlapping blocks or 3780 
 32-bit floating point output values(bins) per descriptor window.
<p>
The number of horizontal overlapping block histogram bins per descriptor window width is determined by
(((oHOGConfig.detectionWindowSize.width / oHOGConfig.histogramBlockSize) * 2) - 1) * oHOGConfig.nHistogramBins.
The number of vertical overlapping block histograms per descriptor window height is determined by 
(((oHOGConfig.detectionWindowSize.height / oHOGConfig.histogramBlockSize) * 2) - 1)
The offset of each descriptor window in the descriptors output buffer is therefore
horizontal histogram bins per descriptor window width * vertical histograms per descriptor window height 32-bit floating point values 
relative to the previous descriptor window output.<p>
The algorithm uses a 1D centered derivative mask of[-1, 0, +1] when generating input magnitude and angle gradients.
Magnitudes are added to the two nearest histogram bins of oriented gradients between 0 and 180 degrees using a weighted linear interpolation of each
magnitude value across the 2 nearest angular bin orientations. 2D overlapping blocks of histogram bins consisting of the bins from 2D arrangements of cells are
then contrast normalized using L2 normalization and output to the corresponding histogram descriptor window for that particular window
location in the window locations list.
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.HLSToBGR.html">NPPNativeMethods.NPPi.HLSToBGR</a></h4>
      <section><p>HLS to BGR</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.HLSToRGB.html">NPPNativeMethods.NPPi.HLSToRGB</a></h4>
      <section><p>HLS to RGB</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.HSVToRGB.html">NPPNativeMethods.NPPi.HSVToRGB</a></h4>
      <section><p>HSV to RGB</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ImageCompression.html">NPPNativeMethods.NPPi.ImageCompression</a></h4>
      <section><p>Image compression primitives.<p>
The JPEG standard defines a flow of level shift, DCT and quantization for
forward JPEG transform and inverse level shift, IDCT and de-quantization
for inverse JPEG transform. This group has the functions for both forward
and inverse functions.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ImageMedianFilter.html">NPPNativeMethods.NPPi.ImageMedianFilter</a></h4>
      <section><p>Result pixel value is the median of pixel values under the rectangular mask region.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ImageProximity.html">NPPNativeMethods.NPPi.ImageProximity</a></h4>
      <section><p>Primitives for computing the proximity measure between a source image and a template image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Integral.html">NPPNativeMethods.NPPi.Integral</a></h4>
      <section><p>Primitives for computing the integral image of a given image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.IQA.html">NPPNativeMethods.NPPi.IQA</a></h4>
      <section><p>Primitives for computing the image quality between two images, such as MSE, PSNR, SSIM, and MS-SSIM.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.LabelMarkers.html">NPPNativeMethods.NPPi.LabelMarkers</a></h4>
      <section><p>Generate image connected region label markers to be used for later image segmentation.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.LabToBGR.html">NPPNativeMethods.NPPi.LabToBGR</a></h4>
      <section><p>LAB to BGR</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.LeftShiftConst.html">NPPNativeMethods.NPPi.LeftShiftConst</a></h4>
      <section><p>Pixel by pixel left shift of an image by a constant value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.LinearFilter1D.html">NPPNativeMethods.NPPi.LinearFilter1D</a></h4>
      <section><p>1D mask Linear Convolution Filter, with rescaling, for 8 bit images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.LinearFixedFilters2D.html">NPPNativeMethods.NPPi.LinearFixedFilters2D</a></h4>
      <section><p>2D linear fixed filters for 8 bit images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.LinearTransforms.html">NPPNativeMethods.NPPi.LinearTransforms</a></h4>
      <section><p>Linear image transforms, like Fourier and DCT transformations.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Ln.html">NPPNativeMethods.NPPi.Ln</a></h4>
      <section><p>Pixel by pixel natural logarithm of each pixel in an image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.LUVToRGB.html">NPPNativeMethods.NPPi.LUVToRGB</a></h4>
      <section><p>LUV to RGB</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Max.html">NPPNativeMethods.NPPi.Max</a></h4>
      <section><p>Maximum</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MaxIdx.html">NPPNativeMethods.NPPi.MaxIdx</a></h4>
      <section><p>Maximum Index</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MaximumError.html">NPPNativeMethods.NPPi.MaximumError</a></h4>
      <section><p>Primitives for computing the maximum error between two images.<p>
Given two images Src1 and Src2 both with width W and height H,
the maximum error is defined as the largest absolute difference between pixels of two images.<p>
If the image is in complex format, the absolute value of the complex number is provided.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MaximumRelativeError.html">NPPNativeMethods.NPPi.MaximumRelativeError</a></h4>
      <section><p>Primitives for computing the maximum relative error between two images.<p>
If the image is in complex format, the absolute value is used for computation.<p>
For multiple channles, the maximum relative error of all the channles is returned.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MeanNew.html">NPPNativeMethods.NPPi.MeanNew</a></h4>
      <section><p>Mean (new in CUDA 5)</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MeanStdDevNew.html">NPPNativeMethods.NPPi.MeanStdDevNew</a></h4>
      <section><p>Mean + Std deviation (new in CUDA 5)</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MemAlloc.html">NPPNativeMethods.NPPi.MemAlloc</a></h4>
      <section><p>Image-Memory Allocation <p>
ImageAllocator methods for 2D arrays of data. The allocators have width and height parameters
to specify the size of the image data being allocated. They return a pointer to the
newly created memory and return the numbers of bytes between successive lines.</p>
<p>
If the memory allocation failed due to lack of free device memory or device memory fragmentation
the routine returns 0.
<p>
All allocators return memory with line strides that are 
beneficial for performance. It is not mandatory to use these allocators. Any valid CUDA device-memory
pointers can be used by the NPP primitives and there are no restrictions on line strides.
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MemCopy.html">NPPNativeMethods.NPPi.MemCopy</a></h4>
      <section><p>Copy methods for images of various types. Images are passed to these primitives via a pointer
to the image data (first pixel in the ROI) and a step-width, i.e. the number of bytes between
successive lines. <p>
The size of the area to be copied (region-of-interest, ROI) is specified via
a Size struct.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MemSet.html">NPPNativeMethods.NPPi.MemSet</a></h4>
      <section><p>Set methods for images of various types. Images are passed to these primitives via a pointer
to the image data (first pixel in the ROI) and a step-width, i.e. the number of bytes between
successive lines. The size of the area to be set (region-of-interest, ROI) is specified via
a Size struct. <p>
In addition to the image data and ROI, all methods have a parameter to specify the value being
set. In case of single channel images this is a single value, in case of multi-channel, an
array of values is passed.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Min.html">NPPNativeMethods.NPPi.Min</a></h4>
      <section><p>Minimum</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MinIdx.html">NPPNativeMethods.NPPi.MinIdx</a></h4>
      <section><p>Minimum index</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MinMaxEvery.html">NPPNativeMethods.NPPi.MinMaxEvery</a></h4>
      <section><p>Primitives for computing the minimal/maximal value of the pixel pair from two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MinMaxIndxNew.html">NPPNativeMethods.NPPi.MinMaxIndxNew</a></h4>
      <section><p>Min / Max Index (new in CUDA 5)</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MinMaxNew.html">NPPNativeMethods.NPPi.MinMaxNew</a></h4>
      <section><p>Min / Max (new in CUDA 5)</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MorphologyFilter2D.html">NPPNativeMethods.NPPi.MorphologyFilter2D</a></h4>
      <section><p>Image dilate and erod operations.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Mul.html">NPPNativeMethods.NPPi.Mul</a></h4>
      <section><p>Pixel by pixel multiply of two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MulConst.html">NPPNativeMethods.NPPi.MulConst</a></h4>
      <section><p>Multiplies each pixel of an image by a constant value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MulConstScale.html">NPPNativeMethods.NPPi.MulConstScale</a></h4>
      <section><p>Multiplies each pixel of an image by a constant value then scales the result by the maximum value for the data bit width.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.MulScale.html">NPPNativeMethods.NPPi.MulScale</a></h4>
      <section><p>Pixel by pixel multiplies each pixel of two images then scales the result by the maximum value for the data bit width.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NormDiff.html">NPPNativeMethods.NPPi.NormDiff</a></h4>
      <section><p>Norm of pixel differences between two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NormInf.html">NPPNativeMethods.NPPi.NormInf</a></h4>
      <section><p>Infinite Norm</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NormL1.html">NPPNativeMethods.NPPi.NormL1</a></h4>
      <section><p>L1 Norm</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NormL2.html">NPPNativeMethods.NPPi.NormL2</a></h4>
      <section><p>L2 Norm</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NormRel.html">NPPNativeMethods.NPPi.NormRel</a></h4>
      <section><p>Primitives for computing the relative error between two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Not.html">NPPNativeMethods.NPPi.Not</a></h4>
      <section><p>Pixel by pixel logical not of image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NV12ToYUV420.html">NPPNativeMethods.NPPi.NV12ToYUV420</a></h4>
      <section><p>NV12 to YUV420 color conversion.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NV21ToBGR.html">NPPNativeMethods.NPPi.NV21ToBGR</a></h4>
      <section><p>NV21 to BGR color conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.NV21ToRGB.html">NPPNativeMethods.NPPi.NV21ToRGB</a></h4>
      <section><p>NV21 to RGB color conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Or.html">NPPNativeMethods.NPPi.Or</a></h4>
      <section><p>Pixel by pixel logical or of images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.OrConst.html">NPPNativeMethods.NPPi.OrConst</a></h4>
      <section><p>Pixel by pixel logical or of an image with a constant.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.PerspectiveTransforms.html">NPPNativeMethods.NPPi.PerspectiveTransforms</a></h4>
      <section><p>Perspective warping, perspective transform calculation
Perspective warping of an image is the transform of image pixel positions,
defined by the following formulas:
\f[
X_{new} = \frac{C_{00} * x + C_{01} * y + C_{02}}{C_{20} * x + C_{21} * y + C_{22}} \qquad
Y_{new} = \frac{C_{10} * x + C_{11} * y + C_{12}}{C_{20} * x + C_{21} * y + C_{22}} \qquad
C = \left[ \matrix{C_{00} &amp; C_{01} &amp; C_{02} \cr C_{10} &amp; C_{11} &amp; C_{12} \cr C_{20} &amp; C_{21} &amp; C_{22} } \right]
\f]
That is, any pixel of the transformed image with coordinates
\f$(X_{new},Y_{new})\f$ has a preimage with
coordinates \f$(x,y)\f$. The mapping \f$C\f$ is fully defined by 8 values
\f$C_{ij}, (i,j)=\overline{0,2}\f$, except of \f$C_{22}\f$, which is a
normalizer.
The transform has a property of mapping any convex quadrangle to a convex
quadrangle, which is used in a group of functions nppiWarpPerspectiveQuad.
The NPPI implementation of perspective transform has some issues which are
discussed in each function's documentation.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.QualityIndex.html">NPPNativeMethods.NPPi.QualityIndex</a></h4>
      <section><p>Primitives for computing the image quality index of two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RankFilters.html">NPPNativeMethods.NPPi.RankFilters</a></h4>
      <section><p>Min, Median, and Max image filters.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Remap.html">NPPNativeMethods.NPPi.Remap</a></h4>
      <section><p>Remap chooses source pixels using pixel coordinates explicitely supplied in two 2D device memory image arrays pointed to by the pXMap and pYMap pointers.<p>
The pXMap array contains the X coordinated and the pYMap array contains the Y coordinate of the corresponding source image pixel to
use as input. These coordinates are in floating point format so fraction pixel positions can be used. The coordinates of the source
pixel to sample are determined as follows:<p>
nSrcX = pxMap[nDstX, nDstY]<p>
nSrcY = pyMap[nDstX, nDstY]<p>
In the Remap functions below source image clip checking is handled as follows:<p>
If the source pixel fractional x and y coordinates are greater than or equal to oSizeROI.x and less than oSizeROI.x + oSizeROI.width and
greater than or equal to oSizeROI.y and less than oSizeROI.y + oSizeROI.height then the source pixel is considered to be within
the source image clip rectangle and the source image is sampled. Otherwise the source image is not sampled and a destination pixel is not
written to the destination image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.ResizeSqrPixel.html">NPPNativeMethods.NPPi.ResizeSqrPixel</a></h4>
      <section><p>Resizes images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToCbYCr.html">NPPNativeMethods.NPPi.RGBToCbYCr</a></h4>
      <section><p>RGB To CbYCr Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToGray.html">NPPNativeMethods.NPPi.RGBToGray</a></h4>
      <section><p>RGB to CCIR601 Gray conversion.<p>
Here is how NPP converts gamma corrected RGB to CCIR601 Gray.<p>
<pre><code>nGray =  0.299F * R + 0.587F * G + 0.114F * B;</code></pre>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToHLS.html">NPPNativeMethods.NPPi.RGBToHLS</a></h4>
      <section><p>RGB to HLS</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToHSV.html">NPPNativeMethods.NPPi.RGBToHSV</a></h4>
      <section><p>RGB to HSV</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToLUV.html">NPPNativeMethods.NPPi.RGBToLUV</a></h4>
      <section><p>RGB to LUV</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToXYZ.html">NPPNativeMethods.NPPi.RGBToXYZ</a></h4>
      <section><p>RGB to XYZ</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToYCbCr.html">NPPNativeMethods.NPPi.RGBToYCbCr</a></h4>
      <section><p>RGB to YCbCr color conversion.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToYCbCr_JPEG.html">NPPNativeMethods.NPPi.RGBToYCbCr_JPEG</a></h4>
      <section><p>JPEG RGB to YCbCr color conversion.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToYCC.html">NPPNativeMethods.NPPi.RGBToYCC</a></h4>
      <section><p>RGB to YCC</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToYCrCb.html">NPPNativeMethods.NPPi.RGBToYCrCb</a></h4>
      <section><p>RGB To YCrCB Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToYUV.html">NPPNativeMethods.NPPi.RGBToYUV</a></h4>
      <section><p>RGB to YUV Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToYUV420.html">NPPNativeMethods.NPPi.RGBToYUV420</a></h4>
      <section><p>RGB to YUV420 Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RGBToYUV422.html">NPPNativeMethods.NPPi.RGBToYUV422</a></h4>
      <section><p>RGB To YUV422 Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.RightShiftConst.html">NPPNativeMethods.NPPi.RightShiftConst</a></h4>
      <section><p>Pixel by pixel right shift of an image by a constant value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.SamplePatternConversion.html">NPPNativeMethods.NPPi.SamplePatternConversion</a></h4>
      <section><p>Sample Pattern Conversion.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Scale.html">NPPNativeMethods.NPPi.Scale</a></h4>
      <section><p>Scale bit-depth up and down.<p>
To map source pixel srcPixelValue to destination pixel dstPixelValue the following equation is used:<p>
dstPixelValue = dstMinRangeValue + scaleFactor * (srcPixelValue - srcMinRangeValue)<p>
where scaleFactor = (dstMaxRangeValue - dstMinRangeValue) / (srcMaxRangeValue - srcMinRangeValue).<p>
For conversions between integer data types, the entire integer numeric range of the input data type is mapped onto
the entire integer numeric range of the output data type.<p>
For conversions to floating point data types the floating point data range is defined by the user supplied floating point values
of nMax and nMin which are used as the dstMaxRangeValue and dstMinRangeValue respectively in the scaleFactor and dstPixelValue
calculations and also as the saturation values to which output data is clamped.<p>
When converting from floating-point values to integer values, nMax and nMin are used as the srcMaxRangeValue and srcMinRangeValue
respectively in the scaleFactor and dstPixelValue calculations. Output values are saturated and clamped to the full output integer
pixel value range.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Sqr.html">NPPNativeMethods.NPPi.Sqr</a></h4>
      <section><p>Square each pixel in an image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Sqrt.html">NPPNativeMethods.NPPi.Sqrt</a></h4>
      <section><p>Pixel by pixel square root of each pixel in an image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Sub.html">NPPNativeMethods.NPPi.Sub</a></h4>
      <section><p>Pixel by pixel subtraction of two images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.SubConst.html">NPPNativeMethods.NPPi.SubConst</a></h4>
      <section><p>Subtracts a constant value from each pixel of an image.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Sum.html">NPPNativeMethods.NPPi.Sum</a></h4>
      <section><p>Sum of 8 bit images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.SwapChannel.html">NPPNativeMethods.NPPi.SwapChannel</a></h4>
      <section><p>Methods for exchanging the color channels of an image. <p>
The methods support arbitrary permutations of the original channels,
including replication.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Threshold.html">NPPNativeMethods.NPPi.Threshold</a></h4>
      <section><p>Threshold pixels.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Transpose.html">NPPNativeMethods.NPPi.Transpose</a></h4>
      <section><p>Methods for transposing images of various types. Like matrix transpose,
image transpose is a mirror along the image's diagonal
(upper-left to lower-right corner).</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.WindowSum1D.html">NPPNativeMethods.NPPi.WindowSum1D</a></h4>
      <section><p>1D mask Window Sum for 8 bit images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.Xor.html">NPPNativeMethods.NPPi.Xor</a></h4>
      <section><p>Pixel by pixel logical exclusive or of images.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.XorConst.html">NPPNativeMethods.NPPi.XorConst</a></h4>
      <section><p>Pixel by pixel logical exclusive or of an image with a constant.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.XYZToRGB.html">NPPNativeMethods.NPPi.XYZToRGB</a></h4>
      <section><p>XYZ to RGB</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YCbCrAndACrCbAndOther.html">NPPNativeMethods.NPPi.YCbCrAndACrCbAndOther</a></h4>
      <section><p>YCbCr ACrCb ...</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YCbCrToBGR.html">NPPNativeMethods.NPPi.YCbCrToBGR</a></h4>
      <section><p>YCbCr To BGR Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YCbCrToRGB.html">NPPNativeMethods.NPPi.YCbCrToRGB</a></h4>
      <section><p>YCbCr to RGB color conversion.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YCCToRGB.html">NPPNativeMethods.NPPi.YCCToRGB</a></h4>
      <section><p>YCC to RGB</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YCrCbToRGB.html">NPPNativeMethods.NPPi.YCrCbToRGB</a></h4>
      <section><p>YCrCB to RGB Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YUV420ToBGR.html">NPPNativeMethods.NPPi.YUV420ToBGR</a></h4>
      <section><p>YUV420 to BGR Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YUV420ToRGB.html">NPPNativeMethods.NPPi.YUV420ToRGB</a></h4>
      <section><p>YUV420 to RGB Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YUV422ToRGB.html">NPPNativeMethods.NPPi.YUV422ToRGB</a></h4>
      <section><p>YUV422 To RGB Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YUVToBGR.html">NPPNativeMethods.NPPi.YUVToBGR</a></h4>
      <section><p>YUV to BGR color conversion.<p>
Here is how NPP converts YUV to gamma corrected RGB or BGR.<p>
Npp32f nY = (Npp32f)Y;<p>
Npp32f nU = (Npp32f)U - 128.0F;<p>
Npp32f nV = (Npp32f)V - 128.0F;<p>
Npp32f nR = nY + 1.140F * nV; <p>
if (nR &lt; 0.0F) nR = 0.0F;<p>
if (nR &gt; 255.0F) nR = 255.0F;<p>
Npp32f nG = nY - 0.394F * nU - 0.581F * nV;<p>
if (nG &lt; 0.0F) nG = 0.0F;<p>
if (nG &gt; 255.0F) nG = 255.0F;<p>
Npp32f nB = nY + 2.032F * nU;<p>
if (nB &lt; 0.0F) nB = 0.0F;<p>
if (nB &gt; 255.0F) nB = 255.0F;</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPi.YUVToRGB.html">NPPNativeMethods.NPPi.YUVToRGB</a></h4>
      <section><p>YUV to RGB Conversion</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.html">NPPNativeMethods.NPPs</a></h4>
      <section><p>npps.h</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AbsoluteValueSignal.html">NPPNativeMethods.NPPs.AbsoluteValueSignal</a></h4>
      <section><p>Absolute value of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AddC.html">NPPNativeMethods.NPPs.AddC</a></h4>
      <section><p>Adds a constant value to each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AddProductC.html">NPPNativeMethods.NPPs.AddProductC</a></h4>
      <section><p>Adds product of a constant and each sample of a source signal to the each sample of destination signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AddProductSignal.html">NPPNativeMethods.NPPs.AddProductSignal</a></h4>
      <section><p>Adds sample by sample product of two signals to the destination signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AddSignal.html">NPPNativeMethods.NPPs.AddSignal</a></h4>
      <section><p>Sample by sample addition of two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.And.html">NPPNativeMethods.NPPs.And</a></h4>
      <section><p>Sample by sample bitwise AND of samples from two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AndC.html">NPPNativeMethods.NPPs.AndC</a></h4>
      <section><p>Bitwise AND of a constant and each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AverageError.html">NPPNativeMethods.NPPs.AverageError</a></h4>
      <section><p>Primitives for computing the Average error between two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.AverageRelativeError.html">NPPNativeMethods.NPPs.AverageRelativeError</a></h4>
      <section><p>Primitives for computing the AverageRelative error between two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Cauchy.html">NPPNativeMethods.NPPs.Cauchy</a></h4>
      <section><p>Determine Cauchy robust error function and its first and second derivatives for each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Convert.html">NPPNativeMethods.NPPs.Convert</a></h4>
      <section><p>Routines for converting the sample-data type of signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Copy.html">NPPNativeMethods.NPPs.Copy</a></h4>
      <section><p>Copy methods for various type signals. Copy methods operate on
signal data given as a pointer to the underlying data-type (e.g. 8-bit
vectors would be passed as pointers to Npp8u type) and length of the
vectors, i.e. the number of items.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.CountInRange.html">NPPNativeMethods.NPPs.CountInRange</a></h4>
      <section><p>Count In Range</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.CubeRootSignal.html">NPPNativeMethods.NPPs.CubeRootSignal</a></h4>
      <section><p>Cube root of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.DivC.html">NPPNativeMethods.NPPs.DivC</a></h4>
      <section><p>Divides each sample of a signal by a constant.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.DivCRev.html">NPPNativeMethods.NPPs.DivCRev</a></h4>
      <section><p>Divides a constant by each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.DivRoundSignal.html">NPPNativeMethods.NPPs.DivRoundSignal</a></h4>
      <section><p>Sample by sample division of the samples of two signals with rounding.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.DivSignal.html">NPPNativeMethods.NPPs.DivSignal</a></h4>
      <section><p>Sample by sample division of the samples of two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.DotProduct.html">NPPNativeMethods.NPPs.DotProduct</a></h4>
      <section><p>Dot Product</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.ExponentSignal.html">NPPNativeMethods.NPPs.ExponentSignal</a></h4>
      <section><p>e raised to the power of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.FilteringFunctions.html">NPPNativeMethods.NPPs.FilteringFunctions</a></h4>
      <section><p>Functions that provide functionality of generating output signal
based on the input signal like signal integral, etc.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.InverseTangentSignal.html">NPPNativeMethods.NPPs.InverseTangentSignal</a></h4>
      <section><p>Inverse tangent of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.LShiftC.html">NPPNativeMethods.NPPs.LShiftC</a></h4>
      <section><p>Left shifts the bits of each sample of a signal by a constant amount.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Max.html">NPPNativeMethods.NPPs.Max</a></h4>
      <section><p>Functions that provide global signal statistics like: average, standard deviation, minimum, etc.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MaximumError.html">NPPNativeMethods.NPPs.MaximumError</a></h4>
      <section><p>Primitives for computing the maximum error between two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MaximumRelativeError.html">NPPNativeMethods.NPPs.MaximumRelativeError</a></h4>
      <section><p>Primitives for computing the MaximumRelative error between two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MeanStdDev.html">NPPNativeMethods.NPPs.MeanStdDev</a></h4>
      <section><p>Mean and StdDev</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MemAlloc.html">NPPNativeMethods.NPPs.MemAlloc</a></h4>
      <section><p>Signal-allocator methods for allocating 1D arrays of data in device memory.
All allocators have size parameters to specify the size of the signal (1D array)
being allocated.</p>
<p>
The allocator methods return a pointer to the newly allocated memory of appropriate
type. If device-memory allocation is not possible due to resource constaints
the allocators return 0 (i.e. NULL pointer). 
<p>
All signal allocators allocate memory aligned such that it is  beneficial to the 
performance of the majority of the signal-processing primitives. 
It is no mandatory however to use these allocators. Any valid
CUDA device-memory pointers can be passed to NPP primitives. 
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Min.html">NPPNativeMethods.NPPs.Min</a></h4>
      <section><p>Functions that provide global signal statistics like: average, standard deviation, minimum, etc.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MinMaxEvery.html">NPPNativeMethods.NPPs.MinMaxEvery</a></h4>
      <section><p>Performs the min or max operation on the samples of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MinMaxIndex.html">NPPNativeMethods.NPPs.MinMaxIndex</a></h4>
      <section><p>Minimum / Maximum values / indices</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MulC.html">NPPNativeMethods.NPPs.MulC</a></h4>
      <section><p>Multiplies each sample of a signal by a constant value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.MulSignal.html">NPPNativeMethods.NPPs.MulSignal</a></h4>
      <section><p>Sample by sample multiplication the samples of two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.NaturalLogarithmSignal.html">NPPNativeMethods.NPPs.NaturalLogarithmSignal</a></h4>
      <section><p>Natural logarithm of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Norm.html">NPPNativeMethods.NPPs.Norm</a></h4>
      <section><p>Infinity Norm, L1 Norm, L2 Norm</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.NormalizeSignal.html">NPPNativeMethods.NPPs.NormalizeSignal</a></h4>
      <section><p>Normalize each sample of a real or complex signal using offset and division operations.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.NormDiff.html">NPPNativeMethods.NPPs.NormDiff</a></h4>
      <section><p>Infinity Norm Diff, L1 Norm Diff, L2 Norm Diff</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Not.html">NPPNativeMethods.NPPs.Not</a></h4>
      <section><p>Bitwise NOT of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Or.html">NPPNativeMethods.NPPs.Or</a></h4>
      <section><p>Sample by sample bitwise OR of samples from two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.OrC.html">NPPNativeMethods.NPPs.OrC</a></h4>
      <section><p>Bitwise OR of a constant and each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.RShiftC.html">NPPNativeMethods.NPPs.RShiftC</a></h4>
      <section><p>Right shifts the bits of each sample of a signal by a constant amount.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Set.html">NPPNativeMethods.NPPs.Set</a></h4>
      <section><p>Set methods for 1D vectors of various types. The copy methods operate on vector data given
as a pointer to the underlying data-type (e.g. 8-bit vectors would
be passed as pointers to Npp8u type) and length of the vectors, i.e. the number of items.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.SquareRootSignal.html">NPPNativeMethods.NPPs.SquareRootSignal</a></h4>
      <section><p>Square root of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.SquareSignal.html">NPPNativeMethods.NPPs.SquareSignal</a></h4>
      <section><p>Squares each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.SubC.html">NPPNativeMethods.NPPs.SubC</a></h4>
      <section><p>Subtracts a constant from each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.SubCRev.html">NPPNativeMethods.NPPs.SubCRev</a></h4>
      <section><p>Subtracts each sample of a signal from a constant.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.SubSignal.html">NPPNativeMethods.NPPs.SubSignal</a></h4>
      <section><p>Sample by sample subtraction of the samples of two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Sum.html">NPPNativeMethods.NPPs.Sum</a></h4>
      <section><p>Functions that provide global signal statistics like: average, standard deviation, minimum, etc.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.SumLn.html">NPPNativeMethods.NPPs.SumLn</a></h4>
      <section><p>Sums up the natural logarithm of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.TenTimesBaseTenLogarithmSignal.html">NPPNativeMethods.NPPs.TenTimesBaseTenLogarithmSignal</a></h4>
      <section><p>Ten times the decimal logarithm of each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Threshold.html">NPPNativeMethods.NPPs.Threshold</a></h4>
      <section><p>Performs the threshold operation on the samples of a signal by limiting the sample values by a specified constant value.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Xor.html">NPPNativeMethods.NPPs.Xor</a></h4>
      <section><p>Sample by sample bitwise XOR of samples from two signals.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.XorC.html">NPPNativeMethods.NPPs.XorC</a></h4>
      <section><p>Bitwise XOR of a constant and each sample of a signal.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.Zero.html">NPPNativeMethods.NPPs.Zero</a></h4>
      <section><p>Set signals to zero.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPNativeMethods.NPPs.ZeroCrossing.html">NPPNativeMethods.NPPs.ZeroCrossing</a></h4>
      <section><p>Count Zero Crossings</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPWarning.html">NPPWarning</a></h4>
      <section><p>WarningException thrown if configured and a native NPP function returns a positive error code</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPWarningHandler.html">NPPWarningHandler</a></h4>
      <section><p>Singleton NPPWarning handler. Use the <a class="xref" href="ManagedCuda.NPP.NPPWarningHandler.html#ManagedCuda_NPP_NPPWarningHandler_OnNPPWarning">OnNPPWarning</a> event
to get notified when a NPP functions returns a NPP warning status code.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPWarningHandler.NPPWarningEventArgs.html">NPPWarningHandler.NPPWarningEventArgs</a></h4>
      <section><p>NPP warning event args</p>
</section>
    <h3 id="structs">Structs
  </h3>
      <h4><a class="xref" href="ManagedCuda.NPP.HaarBuffer.html">HaarBuffer</a></h4>
      <section><p>HaarBuffer</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.HaarClassifier.html">HaarClassifier</a></h4>
      <section><p>HaarClassifier</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.Npp16sc.html">Npp16sc</a></h4>
      <section><p>Complex Number. <p>
This struct represents a short complex number.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.Npp32fc.html">Npp32fc</a></h4>
      <section><p>Complex Number. <p>
This struct represents a single floating-point complex number.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.Npp32sc.html">Npp32sc</a></h4>
      <section><p>Complex Number. <p>
This struct represents a signed int complex number.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.Npp64fc.html">Npp64fc</a></h4>
      <section><p>Complex Number. <p>
This struct represents a double floating-point complex number.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.Npp64sc.html">Npp64sc</a></h4>
      <section><p>Complex Number. <p>
This struct represents a long long complex number.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiColorTwistBatchCXR.html">NppiColorTwistBatchCXR</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiDCTState.html">NppiDCTState</a></h4>
      <section><p>DCT state structure</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiDecodeHuffmanSpec.html">NppiDecodeHuffmanSpec</a></h4>
      <section><p>NppiDecodeHuffmanSpec</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiEncodeHuffmanSpec.html">NppiEncodeHuffmanSpec</a></h4>
      <section><p>NppiEncodeHuffmanSpec</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiGraphcutState.html">NppiGraphcutState</a></h4>
      <section><p>graph-cut state structure</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiHOGConfig.html">NppiHOGConfig</a></h4>
      <section><p>The NppiHOGConfig structure defines the configuration parameters for the HOG descriptor</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiJpegDecodeJob.html">NppiJpegDecodeJob</a></h4>
      <section><p>JPEG decode job used by \ref nppiJpegDecodeJob (see that for more documentation)
The job describes piece of computation to be done.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiJpegDecodeJobMemory.html">NppiJpegDecodeJobMemory</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiJpegFrameDescr.html">NppiJpegFrameDescr</a></h4>
      <section><p>JPEG frame descriptor. Can hold from 1 to 4 components.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiJpegScanDescr.html">NppiJpegScanDescr</a></h4>
      <section><p>JPEG scan descriptor</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiMirrorBatchCXR.html">NppiMirrorBatchCXR</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiPoint.html">NppiPoint</a></h4>
      <section><p>2D Point.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiRect.html">NppiRect</a></h4>
      <section><p>2D Rectangle <p>
This struct contains position and size information of a rectangle in
two space.<p>
The rectangle's position is usually signified by the coordinate of its
upper-left corner.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiResizeBatchCXR.html">NppiResizeBatchCXR</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiSize.html">NppiSize</a></h4>
      <section><p>2D Size <p>
This struct typically represents the size of a a rectangular region in
two space.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiWarpAffineBatchCXR.html">NppiWarpAffineBatchCXR</a></h4>
      <section></section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppLibraryVersion.html">NppLibraryVersion</a></h4>
      <section><p>Npp Library Version.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppPointPolar.html">NppPointPolar</a></h4>
      <section><p>2D Polar Point.</p>
</section>
    <h3 id="enums">Enums
  </h3>
      <h4><a class="xref" href="ManagedCuda.NPP.DifferentialKernel.html">DifferentialKernel</a></h4>
      <section><p>Differential Filter types</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.GpuComputeCapability.html">GpuComputeCapability</a></h4>
      <section><p>Gpu Compute Capabilities</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.InterpolationMode.html">InterpolationMode</a></h4>
      <section><p>Filtering methods</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.MaskSize.html">MaskSize</a></h4>
      <section><p>Fixed filter-kernel sizes.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppCmpOp.html">NppCmpOp</a></h4>
      <section><p>Compare Operator</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppHintAlgorithm.html">NppHintAlgorithm</a></h4>
      <section><p>HintAlgorithm</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiAlphaOp.html">NppiAlphaOp</a></h4>
      <section><p>NppiAlphaOp</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiAxis.html">NppiAxis</a></h4>
      <section><p>Axis</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiBayerGridPosition.html">NppiBayerGridPosition</a></h4>
      <section><p>Bayer Grid Position Registration.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiBorderType.html">NppiBorderType</a></h4>
      <section><p>BorderType</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiHuffmanTableType.html">NppiHuffmanTableType</a></h4>
      <section><p>NppiHuffmanTableType</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiJpegDecodeJobKind.html">NppiJpegDecodeJobKind</a></h4>
      <section><p>Type of job to execute. Usually you will need just SIMPLE
for each scan, one MEMZERO at the beginning and FINALIZE at the end.
See the example in \ref nppiJpegDecodeJob
SIMPLE can be split into multiple jobs: PRE, CPU &amp; GPU.
Please note that if you don't use SIMPLE,
you man need to add some memcopies and synchronizes as
described in \ref nppiJpegDecodeJob.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppiNorm.html">NppiNorm</a></h4>
      <section><p>NppiNorm</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppRoundMode.html">NppRoundMode</a></h4>
      <section><p>Rounding Modes<p>
The enumerated rounding modes are used by a large number of NPP primitives
to allow the user to specify the method by which fractional values are converted
to integer values. Also see \ref rounding_modes.<p>
For NPP release 5.5 new names for the three rounding modes are introduced that are
based on the naming conventions for rounding modes set forth in the IEEE-754
floating-point standard. Developers are encouraged to use the new, longer names
to be future proof as the legacy names will be deprecated in subsequent NPP releases.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppStatus.html">NppStatus</a></h4>
      <section><p>Error Status Codes <p>
Almost all NPP function return error-status information using
these return codes.
Negative return codes indicate errors, positive return codes indicate
warnings, a return code of 0 indicates success.</p>
</section>
      <h4><a class="xref" href="ManagedCuda.NPP.NppsZCType.html">NppsZCType</a></h4>
      <section><p>NppsZCType</p>
</section>
    <h3 id="delegates">Delegates
  </h3>
      <h4><a class="xref" href="ManagedCuda.NPP.NPPWarningHandler.NPPWarningEventHandler.html">NPPWarningHandler.NPPWarningEventHandler</a></h4>
      <section></section>
</article>
          </div>
          
          <div class="hidden-sm col-md-2" role="complementary">
            <div class="sideaffix">
              <div class="contribution">
                <ul class="nav">
                </ul>
              </div>
              <nav class="bs-docs-sidebar hidden-print hidden-xs hidden-sm affix" id="affix">
              <!-- <p><a class="back-to-top" href="#top">Back to top</a><p> -->
              </nav>
            </div>
          </div>
        </div>
      </div>
      
      <footer>
        <div class="grad-bottom"></div>
        <div class="footer">
          <div class="container">
            <span class="pull-right">
              <a href="#top">Back to top</a>
            </span>
            
            <span>Generated by <strong>DocFX</strong></span>
          </div>
        </div>
      </footer>
    </div>
    
    <script type="text/javascript" src="../styles/docfx.vendor.js"></script>
    <script type="text/javascript" src="../styles/docfx.js"></script>
    <script type="text/javascript" src="../styles/main.js"></script>
  </body>
</html>
